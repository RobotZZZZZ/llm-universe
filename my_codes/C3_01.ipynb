{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用api访问Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\".env.local\"))\n",
    "\n",
    "def get_embedding(text: str, model: str = None):\n",
    "    # 获取API KEY\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('ARK_API_KEY'),\n",
    "        base_url=os.getenv('ARK_API_URL'),\n",
    "    )\n",
    "\n",
    "    if not model:\n",
    "        model = os.getenv('ARK_EMBEDDING_MODEL')\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response\n",
    "\n",
    "response = get_embedding(text='要生成 embedding 的输入文本，字符串形式。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreateEmbeddingResponse(data=[Embedding(embedding=[-0.70703125, 2.671875, 0.95703125, -3.484375, -0.421875, -4.03125, 1.4765625, 3.0625, 0.4609375, 0.80859375, -2.21875, 6.3125, 0.18359375, -5.03125, 4.03125, 2.296875, -5.15625, -2.421875, -4.75, -1.3828125, 3.921875, 1.7265625, -1.5703125, -0.9765625, 1.3359375, -0.9453125, -4.40625, -2.609375, -2.453125, 5.71875, 1.5078125, -0.54296875, -2.546875, 1.9609375, -2.765625, 3.734375, -1.90625, -11.5, -6.125, -0.447265625, -3.390625, 0.27734375, -1.828125, -1.2109375, 3.359375, 3.609375, -1.140625, -3.0, 6.125, -1.84375, -1.703125, 5.9375, -0.95703125, 0.220703125, 3.859375, 0.85546875, -0.29296875, 2.4375, 1.5546875, -5.15625, 4.625, -3.390625, 1.375, -1.53125, -3.421875, 3.8125, -2.828125, -3.125, -0.9609375, -0.384765625, -3.015625, -0.4765625, 2.078125, -2.140625, 0.1748046875, 0.609375, -2.296875, 2.109375, -5.0625, 3.390625, -1.2109375, 0.39453125, 0.419921875, 0.74609375, 0.95703125, -2.15625, -2.25, 1.53125, -0.1591796875, -3.90625, -4.34375, -5.5, 2.390625, -2.625, -4.4375, 0.67578125, 4.84375, -3.1875, -4.0625, -0.050537109375, -1.5546875, -3.3125, 6.5, 3.40625, 7.46875, 2.078125, 3.921875, -2.015625, 3.328125, -2.09375, 3.203125, 3.046875, -0.091796875, 0.92578125, -4.3125, -2.671875, -1.203125, 2.109375, 3.625, -3.515625, -2.09375, 0.287109375, 2.84375, -0.2109375, 0.2734375, 1.953125, -7.5625, -3.03125, 0.365234375, -2.421875, 1.2890625, -0.91796875, 1.203125, 1.453125, -0.357421875, -2.578125, 3.40625, 2.5, -4.1875, -1.9375, -0.119140625, -7.4375, 0.0302734375, -0.296875, 3.109375, -1.5546875, -2.21875, -1.515625, -2.046875, 4.28125, -2.90625, -0.423828125, -0.0257568359375, 0.91796875, -0.185546875, -1.4765625, 1.875, 1.96875, -1.421875, -1.2265625, -1.0078125, -0.94921875, 0.470703125, -3.046875, 0.96875, -4.09375, -2.3125, -1.75, 2.515625, 1.234375, 1.5625, 0.88671875, 0.75390625, 5.625, 2.234375, -3.1875, 1.28125, 0.031494140625, -0.515625, 3.03125, 1.8828125, 1.0625, 3.109375, -0.0341796875, -2.234375, 0.58984375, -3.875, 0.85546875, 1.4453125, 0.84375, 0.23828125, -0.65625, 1.6484375, -0.419921875, 3.625, -1.15625, -0.7109375, 1.7265625, -2.546875, -1.5859375, -2.71875, 2.5, -3.46875, -1.328125, 0.478515625, 0.97265625, -3.1875, -1.9453125, 1.421875, 4.09375, 3.578125, 1.6328125, 0.2412109375, -4.1875, 3.15625, -0.439453125, -0.83984375, 1.625, 2.78125, -2.9375, -2.703125, -1.28125, -2.21875, -4.21875, 7.1875, -0.69921875, -1.6015625, -1.28125, 0.01361083984375, 0.9765625, 3.859375, -3.71875, 2.28125, 0.3359375, -1.578125, -2.296875, -0.1689453125, -1.734375, 1.28125, -1.9453125, -1.15625, -2.65625, -2.359375, 0.359375, -5.15625, 2.84375, -0.1533203125, 1.5625, -3.28125, 1.5703125, -0.376953125, -1.34375, -1.0390625, 1.4140625, -1.09375, -2.671875, -2.5625, 1.3203125, -0.5390625, -0.380859375, 1.765625, -3.015625, -0.193359375, 2.140625, -3.734375, -0.9765625, 0.052490234375, 1.7109375, 1.46875, -0.8125, 0.3984375, -0.162109375, 1.3671875, 1.078125, 0.59765625, 1.9140625, 1.1953125, 2.71875, -3.9375, -4.34375, -1.0, -0.392578125, -2.3125, 0.9609375, 3.0, 3.625, 1.78125, -1.2109375, -2.0625, 1.1875, -4.40625, 2.796875, -0.419921875, 0.96484375, 1.109375, 0.56640625, 1.796875, 0.07421875, -0.439453125, -1.28125, -3.6875, 2.21875, 2.5625, -1.4296875, 3.96875, -3.671875, -0.77734375, 2.578125, 0.03369140625, -0.326171875, -4.1875, 1.6171875, -0.9140625, -2.640625, -1.578125, 3.4375, 2.1875, -0.53515625, 5.15625, -2.65625, 2.046875, -0.59375, 2.59375, 3.40625, 1.671875, 2.515625, 0.90625, -1.2109375, 1.1953125, -4.21875, 6.15625, 0.8984375, 6.0625, 1.171875, -2.15625, 1.4453125, 1.0703125, 0.296875, 0.609375, 2.40625, -0.5390625, -0.34375, 1.7109375, 0.1201171875, -1.578125, -0.388671875, -1.140625, -0.7578125, 1.8203125, -2.921875, -0.40625, 2.125, -2.796875, -0.63671875, 1.4765625, 3.703125, 3.625, 1.65625, 5.09375, 2.390625, 0.70703125, 0.369140625, -0.83203125, -3.203125, -0.310546875, 2.015625, -2.609375, 0.474609375, 5.40625, -2.765625, -1.6484375, 2.578125, -1.5, -7.8125, -4.875, 0.203125, -1.34375, 1.4140625, -3.5, 3.484375, -0.86328125, -0.94921875, -3.734375, 1.03125, -8.625, 0.78515625, -0.79296875, -2.6875, 0.310546875, 1.875, 2.5, -0.8828125, 0.30859375, 0.091796875, -2.421875, -3.484375, 0.8125, 1.3046875, 2.09375, 1.625, 2.828125, -0.1669921875, -3.390625, -1.046875, -1.296875, -1.0703125, -0.16796875, 1.3828125, 2.4375, -5.125, 3.921875, -1.9609375, -3.234375, 2.0625, 1.9921875, -3.796875, -2.15625, -0.43359375, 1.0546875, -1.90625, -2.34375, -2.0625, 2.8125, 0.10107421875, -1.53125, -0.7734375, 0.03466796875, 1.1015625, -3.046875, 2.21875, 0.5, -5.0, -0.71484375, -0.921875, 4.0, -3.0, -1.828125, 1.9921875, 1.8125, 0.42578125, 3.4375, -4.375, 1.953125, -1.25, -5.59375, 5.0, 0.369140625, -3.234375, 1.015625, 2.75, 0.6796875, -1.9296875, -0.97265625, -0.10498046875, -2.78125, -4.03125, 5.59375, 0.443359375, -0.640625, 4.8125, 1.40625, -0.66015625, 1.3203125, 1.3671875, -2.453125, -3.25, -1.515625, 1.703125, 0.77734375, 2.78125, -2.921875, 2.859375, 4.15625, -0.8203125, 3.46875, 1.34375, -3.921875, 0.80078125, 1.75, 1.9609375, -3.859375, -1.5234375, -3.859375, -1.265625, 2.453125, 1.140625, 0.69140625, -3.515625, 2.625, -3.046875, 2.0625, 1.0078125, 2.625, -4.28125, -2.078125, 3.921875, -2.609375, 0.431640625, 2.8125, -4.46875, -1.921875, 0.298828125, -0.59375, -4.5625, -1.7734375, 2.125, -1.375, 0.1005859375, 0.7265625, -1.203125, 0.8671875, -1.78125, 1.8671875, -4.09375, 7.25, -2.296875, 0.71875, -3.859375, 1.0, -2.109375, 2.1875, -1.890625, -4.25, 4.1875, 1.546875, -2.234375, -0.51953125, 1.671875, -1.015625, -0.7421875, -2.890625, -0.0595703125, -2.21875, -0.8671875, 1.25, -8.375, -1.0703125, -1.1953125, 0.462890625, -0.984375, -3.3125, 0.51171875, -1.1875, -0.94921875, 4.53125, 1.09375, 0.01519775390625, 4.5625, 2.015625, -2.234375, -1.65625, -1.8046875, 2.171875, -1.9765625, -2.9375, -4.3125, -1.1875, 3.625, -0.64453125, -12.375, -1.7109375, 2.15625, -0.77734375, -3.203125, 1.4453125, -3.40625, -1.3046875, 0.83203125, -0.294921875, -0.93359375, -4.40625, -2.53125, 3.3125, 0.0595703125, -0.90625, -2.328125, 0.6640625, 1.59375, -0.28515625, -4.9375, -3.734375, -2.078125, -0.51953125, 2.078125, -3.03125, 0.0458984375, 1.8125, 0.79296875, 3.328125, -0.6953125, 1.71875, -0.77734375, 0.48828125, -0.302734375, -6.46875, -3.84375, -3.703125, -2.4375, -4.5625, -1.796875, 0.83984375, -1.28125, 0.055419921875, 4.25, -2.453125, -1.0625, -1.5625, -0.486328125, 0.455078125, 0.05322265625, -0.498046875, -1.0703125, -0.1923828125, -0.9609375, 1.9609375, -0.11376953125, 2.46875, -1.3828125, -1.0078125, 0.89453125, -1.203125, 0.462890625, -0.9765625, -2.71875, -0.63671875, 2.78125, 0.3671875, -5.1875, -0.734375, 1.921875, 2.953125, 0.5078125, 1.5703125, 0.4140625, 2.203125, -1.6640625, 1.890625, 2.03125, -3.046875, 2.265625, -0.6953125, -1.7109375, 3.546875, 1.9765625, -7.03125, 0.515625, -1.25, -0.44140625, 0.41796875, 4.96875, -0.392578125, -3.59375, -0.55078125, -2.09375, 0.6171875, -0.69140625, 0.53125, -3.0625, 0.267578125, -0.65234375, 2.4375, 0.4765625, -1.96875, 0.5625, 3.15625, -2.25, 1.0703125, -4.1875, 0.56640625, -4.125, -3.875, 3.109375, -2.859375, 2.359375, 1.8359375, 1.0546875, 2.15625, -0.09716796875, 0.119140625, 2.3125, -1.21875, -0.68359375, -2.53125, -0.10791015625, -3.21875, -1.1796875, 3.03125, -4.3125, -0.703125, -1.6875, 3.140625, -2.71875, 2.8125, 1.84375, -0.154296875, 3.421875, 1.59375, -1.4453125, 1.8125, 2.296875, -1.2109375, -0.76171875, -3.125, -1.8515625, 2.671875, 2.734375, -2.890625, -0.2392578125, 3.28125, 1.3515625, 0.97265625, -0.69921875, 1.4765625, -1.546875, 1.203125, 0.130859375, 4.34375, 0.875, 0.1435546875, 1.796875, 2.0625, 0.0859375, 0.4375, -1.5234375, -2.828125, -0.6484375, -2.546875, -5.0, 3.03125, 3.578125, 1.0859375, -2.109375, -3.28125, -0.0888671875, -0.91796875, 5.0, -0.134765625, -0.76953125, 1.640625, 2.265625, -6.78125, -0.396484375, 0.88671875, 1.75, 1.1171875, 3.828125, -2.5625, -2.546875, -3.84375, -0.7265625, 2.40625, -2.484375, -2.015625, -3.65625, -1.75, -1.21875, -2.6875, 1.3046875, -1.1875, -4.1875, -3.203125, 1.09375, 0.70703125, -4.53125, -0.828125, -3.578125, -4.65625, -1.2109375, -2.40625, -1.3828125, 0.5859375, -2.921875, -0.984375, -1.4921875, 0.71875, -1.0078125, 3.296875, -1.828125, -2.359375, -0.59765625, -4.21875, -2.109375, -1.3359375, -3.0, 1.046875, 1.265625, 6.9375, 0.4609375, -1.1953125, 1.0390625, 1.71875, 0.5234375, -1.9375, 0.0439453125, 1.421875, -2.484375, 0.375, 1.0546875, -4.25, 0.70703125, -1.390625, 8.0625, -0.34375, 0.98046875, -2.890625, 0.80859375, -2.828125, 0.71875, 1.78125, -2.671875, 0.6015625, -0.6875, 0.2578125, 0.059326171875, -3.21875, -1.203125, 1.21875, -0.953125, -0.38671875, 1.5625, -0.263671875, 0.419921875, 3.59375, 2.046875, -1.3359375, -1.15625, -0.91015625, -0.5234375, 0.9921875, 0.330078125, -2.65625, 1.734375, 1.2734375, 4.875, -1.2421875, -1.5703125, -2.78125, -4.53125, -1.328125, 1.140625, 1.6015625, -3.15625, 0.17578125, 4.03125, -0.2119140625, 1.796875, -2.875, -3.890625, 2.0625, -3.453125, -0.52734375, 1.4921875, 2.359375, 0.26953125, 3.34375, -1.2265625, -3.453125, -2.984375, -1.125, -1.234375, 2.75, -0.9296875, 1.34375, 0.490234375, 5.6875, -1.2265625, -0.8359375, -3.515625, 1.71875, -4.4375, 0.4296875, 3.390625, -2.84375, -0.1826171875, -3.734375, 1.4375, -1.296875, 0.5390625, -2.921875, -1.828125, 0.4453125, -3.9375, -0.28515625, 3.046875, 1.171875, 1.515625, -2.546875, 0.52734375, 3.59375, -4.3125, -0.1533203125, -2.25, -2.75, -0.5546875, -2.859375, 1.8671875, -2.40625, -0.86328125, -0.69140625, -0.109375, -0.81640625, -2.015625, 2.296875, -5.625, 1.78125, -2.875, 1.9140625, 0.205078125, -2.09375, 1.453125, 0.408203125, -0.087890625, 2.453125, -1.21875, 0.54296875, -2.3125, -0.8125, 2.21875, -0.1982421875, -2.21875, 0.404296875, 0.1845703125, 2.296875, -0.2578125, -1.328125, 7.625, 0.1513671875, 0.2197265625, 1.359375, 0.9296875, 0.8203125, -2.21875, 2.578125, -0.162109375, -1.7734375, -3.765625, -8.0, -0.185546875, 2.5625, 1.0625, 1.5390625, -2.8125, 2.859375, 2.640625, 1.15625, 1.7890625, 1.4296875, -0.400390625, 2.515625, 1.5390625, -2.9375, -1.265625, -1.9921875, -5.0625, -3.671875, 2.8125, -1.875, 0.263671875, 0.84765625, 2.421875, -1.6796875, -1.7265625, -3.0625, -0.0830078125, 0.70703125, 1.8203125, 2.125, 1.2578125, -3.96875, -2.859375, 3.5625, -0.80078125, 2.484375, -4.375, 2.125, -4.625, -2.484375, 0.265625, -1.3671875, 2.078125, -0.09619140625, -0.9140625, 1.6171875, -3.515625, -4.03125, 3.0625, -1.53125, 1.828125, -2.59375, 0.451171875, 2.828125, -0.55078125, -3.765625, 3.53125, 0.173828125, -2.078125, 1.859375, -0.279296875, -1.609375, -1.046875, 0.94921875, 2.953125, 2.453125, -0.90625, 2.859375, -3.4375, -1.3125, 2.234375, -3.921875, 2.578125, -0.38671875, -2.84375, 2.59375, 0.79296875, 4.875, 1.6640625, -3.8125, 0.9921875, 1.984375, -0.0537109375, 1.5546875, 1.734375, 0.9765625, -2.484375, 1.9453125, -2.890625, 3.09375, -2.625, 0.2421875, -11.375, -3.25, 3.234375, 1.453125, -2.546875, -0.828125, -1.625, 0.15234375, 1.734375, 0.1591796875, 5.5625, -0.76171875, 1.1640625, -1.046875, 2.015625, 24.375, -0.392578125, 0.71484375, -0.12158203125, -0.62109375, 2.015625, -1.5390625, 2.921875, -2.203125, 1.1328125, -0.40234375, -1.3125, 0.9921875, 2.109375, 2.796875, 2.046875, -0.326171875, -2.03125, -2.703125, 3.0625, -4.4375, 0.36328125, -1.265625, -0.5078125, -1.7421875, 0.1103515625, 2.515625, 2.171875, -0.12451171875, 2.140625, 2.671875, -4.8125, 2.171875, -0.1748046875, 1.453125, -0.546875, 1.0859375, -0.84765625, -0.96875, 2.859375, -0.84375, -5.53125, 3.359375, -0.416015625, 1.53125, -1.5078125, -0.5078125, 3.546875, 0.81640625, 0.1982421875, 2.203125, -4.21875, 1.2578125, -0.6640625, 1.546875, 0.89453125, 0.330078125, 1.75, -1.4140625, 2.453125, -4.65625, 3.609375, 2.703125, -0.8984375, 0.31640625, 3.109375, -2.71875, 0.3125, -0.5234375, -2.28125, 0.68359375, 2.3125, 0.94921875, 0.56640625, 2.25, 0.361328125, 1.2578125, -1.46875, 0.470703125, -0.99609375, -0.94921875, 1.0078125, 0.7421875, -1.1953125, 0.126953125, -0.314453125, -0.6015625, -1.875, -0.2578125, 1.7109375, -1.8203125, -1.296875, -3.875, 4.6875, 3.484375, -1.203125, -0.92578125, 1.1328125, 1.9375, -2.828125, -1.953125, -1.96875, 0.60546875, -0.125, -1.234375, 1.5, -1.6796875, -2.859375, -3.703125, 1.84375, 2.0625, 0.032958984375, -3.078125, -1.0078125, -1.6328125, 2.15625, -3.09375, -3.5, -2.46875, 0.94140625, 3.765625, -2.609375, 1.4921875, 0.94140625, -0.40234375, 2.828125, -0.447265625, 1.84375, -2.515625, -3.171875, 0.455078125, 0.1982421875, -1.5546875, -0.546875, -1.953125, -0.49609375, -2.265625, -1.7265625, 2.5625, 0.546875, -2.28125, -0.333984375, 1.375, -3.703125, 1.421875, 3.265625, -0.73828125, 0.1650390625, 3.671875, -2.921875, 3.03125, 5.25, 0.208984375, -1.9609375, 1.796875, -1.015625, -0.1494140625, -2.515625, -3.984375, -2.25, 1.2578125, 3.3125, -2.734375, -1.2734375, -1.5703125, -0.7578125, 0.5859375, -1.1171875, 0.62890625, -4.6875, -1.15625, -0.80078125, -2.3125, -2.328125, 0.61328125, -1.9375, 2.421875, 1.34375, -0.19921875, 0.3515625, -3.8125, -0.73046875, 1.125, 1.5390625, -0.515625, 1.2578125, -0.484375, -1.6171875, -3.90625, 0.828125, -0.8984375, 0.4375, 1.8828125, -0.4296875, -0.50390625, -0.3515625, -0.69140625, -1.9609375, -0.0615234375, -1.078125, -1.0390625, 1.6015625, -2.515625, -0.5859375, 0.95703125, -0.9765625, 2.046875, -2.0, 0.17578125, 2.28125, 1.078125, -1.8203125, -4.125, 1.7109375, 2.265625, -3.234375, -0.48046875, -0.64453125, 0.62109375, -2.046875, 2.03125, -1.015625, 2.78125, -0.7109375, -6.28125, 0.78515625, -1.3515625, 2.921875, -1.40625, 4.28125, -0.365234375, -2.0625, -1.421875, 2.578125, 0.2578125, 1.8125, 1.25, 0.44921875, -0.7734375, -1.3359375, -0.318359375, 2.171875, 0.49609375, 1.3828125, -1.9453125, 0.84765625, -1.328125, 0.78515625, -0.53125, 1.546875, 2.125, 2.015625, 0.265625, 0.294921875, -0.458984375, -2.578125, -0.408203125, -4.03125, -1.0234375, 2.640625, 2.296875, 3.640625, 1.3125, 2.234375, -0.72265625, 1.0546875, 1.921875, -2.671875, -1.5078125, -2.1875, -0.7734375, 1.4921875, -1.328125, 2.796875, 0.2734375, 0.58984375, 4.75, -3.8125, -2.09375, -0.08447265625, -2.59375, -1.421875, -0.416015625, 0.061767578125, 1.8828125, -1.8984375, 0.365234375, 0.16796875, 3.09375, -0.45703125, 1.984375, -0.56640625, -1.3828125, 0.031005859375, -0.2333984375, 2.046875, 1.90625, 0.2041015625, 2.578125, -1.1640625, -2.875, 0.482421875, -0.267578125, 3.828125, -0.35546875, -0.421875, -0.67578125, -3.109375, 2.78125, -3.03125, -0.88671875, -1.578125, -2.671875, -1.5703125, 4.375, 1.1640625, 0.61328125, -0.275390625, -3.296875, 0.6796875, -1.3515625, -0.81640625, 2.3125, 1.6171875, 0.0277099609375, -1.0859375, 2.609375, 0.431640625, -2.4375, -1.421875, -0.98046875, 4.46875, -1.8828125, 1.9140625, -0.87890625, -3.578125, -0.89453125, -0.7421875, 0.2080078125, -1.9765625, 2.125, 0.1455078125, -2.046875, 2.65625, -1.2421875, -3.5, -1.46875, -0.0211181640625, 1.828125, -1.875, -0.5078125, 2.59375, -0.7265625, 2.140625, 0.97265625, 1.3671875, -0.640625, -3.65625, -2.03125, 1.3046875, -1.21875, -3.140625, -2.65625, 0.431640625, 2.484375, 0.3515625, -4.875, 2.921875, -0.45703125, 2.109375, -0.54296875, -1.625, 0.87109375, -1.2890625, 3.125, 1.4296875, -1.859375, 1.4609375, 0.7421875, 1.3828125, -0.79296875, -1.2890625, 2.921875, -0.373046875, 1.96875, 3.375, -0.98046875, -3.109375, -1.140625, -5.5625, 0.234375, -3.6875, 0.609375, -10.9375, -3.1875, 0.365234375, 0.0732421875, -0.828125, -1.5, -1.6484375, -2.40625, -2.34375, 0.3046875, -0.294921875, 1.0078125, -1.6328125, 1.25, -1.2890625, -1.6875, -2.109375, -0.89453125, -2.265625, -0.474609375, 1.3359375, 3.5625, 1.4765625, 0.2275390625, -2.3125, -0.57421875, -0.9765625, 1.3984375, 1.8671875, -1.8515625, -2.328125, -1.7578125, 1.9375, -1.4609375, -0.6484375, -1.796875, 3.75, 1.2578125, -0.32421875, 2.21875, -0.63671875, -1.984375, 7.09375, -1.1484375, 3.1875, -1.4296875, -3.015625, -3.109375, 4.3125, 2.0, 1.0625, 3.171875, 0.6171875, -2.015625, -0.8125, -2.265625, 2.4375, -1.859375, -2.53125, 0.61328125, -4.375, 1.3359375, -4.34375, -1.7265625, -1.6796875, -0.84375, 0.498046875, 3.125, -2.484375, 1.625, -0.75390625, -1.9609375, -0.640625, 0.90234375, -0.44921875, 1.7734375, 0.173828125, -0.0030670166015625, 0.322265625, 0.859375, 1.7890625, 2.546875, -0.40625, -1.0546875, -4.28125, -1.5078125, 1.8515625, -0.68359375, 0.12255859375, -2.828125, -0.4765625, -0.103515625, -0.154296875, -1.671875, -1.640625, -3.078125, -2.03125, 0.46484375, 0.11669921875, -3.890625, -1.1328125, -0.3125, -0.44921875, -4.9375, -1.890625, 3.5625, -1.3984375, -1.0546875, -4.125, -2.53125, -2.75, -0.37109375, -1.59375, 1.40625, -1.1171875, 0.33203125, 2.5, -3.359375, 0.34765625, -1.4921875, -0.232421875, 0.265625, -0.5, -0.0341796875, 2.609375, -2.328125, 1.6640625, 0.5234375, 0.59765625, 2.578125, -0.353515625, 0.3671875, 1.0, -0.7890625, -1.1328125, 5.0625, 2.953125, 3.53125, -1.1875, -3.921875, -2.53125, -2.375, -3.9375, -2.203125, 1.140625, 0.49609375, -3.453125, 0.625, -0.458984375, -0.90234375, 1.375, 1.1171875, -1.765625, -0.20703125, -0.005340576171875, 1.90625, 0.83203125, 0.90625, 3.1875, -1.8203125, 2.109375, 0.94140625, 0.7578125, -5.0, -3.28125, 1.015625, -1.6796875, -3.5, 2.375, 2.109375, -1.1640625, -3.421875, 0.1962890625, 0.07568359375, 4.34375, -0.96484375, -1.078125, -3.0, 1.9609375, -1.3046875, -1.109375, 2.625, 4.15625, 0.416015625, -6.15625, 1.203125, -0.466796875, -3.453125, -0.349609375, 2.078125, 1.6953125, 1.2109375, 3.96875, -1.2578125, 1.125, -2.234375, -2.71875, 1.4296875, 3.328125, 0.25, 1.140625, -1.90625, 0.58984375, -0.29296875, -1.5390625, 1.1171875, 3.6875, -4.34375, 3.34375, -0.4140625, -0.59765625, 0.77734375, 1.2734375, 0.10693359375, -2.6875, 3.34375, 6.78125, 0.08447265625, -3.65625, -0.150390625, -0.0025482177734375, -0.7109375, 1.0546875, -2.734375, -1.8203125, 2.953125, -1.6796875, -3.6875, -0.404296875, -1.890625, 0.0400390625, 0.3046875, 1.96875, 1.4921875, -0.28125, -0.38671875, 1.078125, -2.34375, -3.21875, -2.265625, -1.2421875, -0.05224609375, 1.0390625, 0.59375, -2.8125, -1.3515625, -1.0078125, -0.8125, 1.578125, -1.421875, 1.0546875, 1.9296875, 0.53515625, -1.5625, -3.140625, 0.62890625, -0.6171875, 3.1875, 0.46484375, -1.6171875, 1.4609375, -4.1875, -0.74609375, 0.55078125, -0.0034942626953125, -0.52734375, 1.0390625, -0.78125, 9.0, 0.76171875, -2.25, 2.5, -1.703125, -1.09375, -0.69921875, -2.359375, -1.984375, 2.25, -2.109375, -2.359375, -1.8671875, 1.859375, 2.234375, -2.15625, -4.21875, -2.59375, -3.71875, -1.875, -0.890625, -2.640625, 4.5625, -2.03125, 2.71875, -3.453125, 1.6796875, 1.421875, 0.98046875, 1.15625, 2.578125, -4.71875, 0.412109375, 0.427734375, -0.435546875, 1.109375, -1.7109375, 2.5, -3.1875, 2.4375, -2.6875, -0.72265625, -0.6875, 2.921875, -3.953125, -0.94921875, -0.43359375, 3.0, 0.00286865234375, 1.2734375, -0.0245361328125, 0.1083984375, -1.5703125, 0.40234375, 1.09375, -0.41015625, 1.6640625, -0.7421875, -2.296875, -0.115234375, -0.5625, -3.578125, -4.15625, 1.796875, 1.953125, 2.359375, -2.03125, -2.171875, -0.6171875, 0.1923828125, 0.453125, -3.5, 0.6796875, -0.11083984375, 4.03125, -1.2734375, 1.140625, -3.1875, 0.8203125, -0.6171875, -1.96875, 0.8359375, 0.98046875, -1.140625, -0.59765625, 4.03125, 2.234375, -0.035888671875, 2.0625, -0.54296875, -2.875, -4.09375, 0.9375, 0.546875, 1.265625, 4.21875, -0.84375, 2.0, 1.75, -2.03125, 0.98046875, -2.78125, 2.625, 2.140625, -2.0, -1.734375, 2.015625, -3.25, 0.0272216796875, -1.359375, -0.353515625, -1.59375, 2.828125, 1.3046875, -1.796875, 0.70703125, 0.203125, -0.58984375, 1.2734375, 0.232421875, 2.0625, -1.125, -1.75, 2.53125, 1.40625, -3.375, 1.5, -3.09375, -0.333984375, 3.390625, 1.9140625, -1.2421875, -1.1953125, -1.2734375, -1.3671875, 1.03125, 0.70703125, -1.5546875, 4.875, -0.71484375, -0.01806640625, -3.109375, 0.1728515625, 0.474609375, 0.201171875, -1.1875, -0.408203125, -0.058837890625, -1.8984375, -0.1708984375, -0.83203125, 2.578125, 1.421875, 1.7109375, -1.1796875, 0.34375, -0.162109375, 0.33984375, 4.28125, 0.76171875, 2.140625, 1.3515625, -0.10986328125, -1.875, -2.203125, -1.0390625, 3.59375, 0.921875, 1.8046875, -0.09130859375, -3.828125, -1.0859375, 4.0625, 3.640625, -0.212890625, -0.06298828125, 1.625, -0.96484375, -0.75, 0.30078125, 2.65625, -1.609375, 1.3828125, -0.87890625, 0.98046875, 0.359375, -4.65625, -0.478515625, 1.9453125, 0.05810546875, 4.59375, -0.58984375, -0.52734375, 1.9375, 1.734375, -2.484375, -3.25, -0.84375, -1.453125, -0.59765625, -2.515625, -1.265625, 3.140625, 2.75, -2.8125, 1.84375, -1.0078125, -2.359375, -0.134765625, -1.046875, 1.3515625, 0.52734375, 1.9765625, 3.015625, -0.1796875, 0.97265625, 0.765625, -0.392578125, 1.265625, -1.015625, 0.9140625, -1.53125, 3.890625, -2.203125, 2.40625, -1.296875, -0.921875, -4.15625, -0.337890625, -0.09521484375, -0.59375, 2.015625, 0.58984375, 0.62109375, 3.484375, -3.03125, -0.71875, 1.640625, 0.9765625, -0.70703125, 3.09375, -3.5, -4.09375, 3.5625, 3.625, -2.546875, 0.9453125, -0.3515625, 4.0, 2.8125, -1.65625, 1.4453125, -3.71875, 0.6328125, 1.578125, -1.2421875, 1.75, -0.130859375, -1.7109375, -3.1875, -1.2890625, 1.7265625, -0.2109375, -5.03125, 3.40625, 1.7421875, -0.890625, -0.6796875, 0.59765625, -0.158203125, -1.265625, -3.59375, 1.21875, -0.51953125, 3.484375, -0.7578125, -2.90625, 4.0625, -2.765625, -0.94140625, 0.4609375, 0.021484375, -1.84375, 1.125, 0.80859375, 1.5859375, 1.6953125, -0.6875, -2.40625, 3.71875, 1.28125, -0.71875, 0.62890625, -1.9609375, -3.59375, 3.140625, -1.4609375, -1.0859375, -0.9609375, -1.1953125, 3.234375, 2.453125, 1.5859375, 1.671875, -2.171875, 0.2001953125, 7.6875, 1.5, -2.328125, -0.52734375, 0.8515625, -2.5, 1.859375, -2.28125, -3.390625, 1.1328125, 1.7265625, -0.51171875, -1.8515625, 2.4375, 0.625, 1.7421875, -1.453125, -0.65625, 0.326171875, 2.453125, 2.46875, 1.3671875, -1.9921875, -3.015625, 0.703125, -1.4140625, 1.8125, -2.765625, -0.25, -3.015625, 0.1171875, 0.4296875, 1.2265625, -2.875, -0.9609375, -2.75, -3.890625, -2.078125, -0.423828125, 0.82421875, -0.283203125, -0.0859375, -0.890625, 0.72265625, 0.7421875, 1.8828125, 0.54296875, 0.04638671875, -0.76953125, -0.279296875, 0.359375, -0.50390625, -0.33203125, 0.2578125, -3.578125, 0.3125, 1.21875, -1.3046875, -1.46875, 0.359375, 0.9296875, -1.0859375, 2.296875, 3.203125, -0.1962890625, -0.036376953125, 0.353515625, -0.13671875, -0.416015625, 1.0625, 1.1328125, 1.8984375, 0.470703125, -0.2421875, 2.78125, -0.54296875, -0.380859375, -2.1875, 1.0546875, 0.1767578125, -0.63671875, 1.484375, 0.75390625, 0.63671875, 1.9453125, -1.1640625, -0.1865234375, -0.98828125, -1.953125, -0.61328125, 0.765625, -0.1513671875, 1.140625, 0.83984375, -0.56640625, -0.6015625, -0.2158203125, -0.11767578125, 0.37890625, -1.296875, 1.828125, -0.359375, 1.4765625, 2.21875, 0.162109375, 0.412109375, -1.6171875, -0.83203125, 0.75, 0.052978515625, 0.61328125, 0.96484375, 1.3125, 1.0546875, -0.06884765625, 0.5234375, 1.375, -1.25, -0.76171875, -0.2890625, -2.171875, -0.1748046875, 1.6015625, -0.69921875, 1.3125, -0.73046875, 1.0703125, 0.65234375, -1.515625, -0.796875, -1.5859375, -0.6328125, 1.1015625, 1.3359375, 0.53515625, 1.0625, -1.4296875, -2.484375, 0.1298828125, 1.59375, 0.396484375, -1.015625, -0.94140625, 1.2578125, 0.7578125, 0.96875, 0.37109375, 0.93359375, -0.04833984375, 2.96875, -0.349609375, -1.828125, -0.5390625, 1.53125, -2.09375, 0.890625, 0.98828125, 0.326171875, 0.302734375, -0.298828125, 0.35546875, -0.66015625, -0.6015625, 1.46875, -1.0625, -1.1640625, 0.25390625, 2.84375, -1.0859375, -1.609375, 2.25, 1.96875, 1.0234375, -0.04345703125, -0.1689453125, -1.6015625, 0.54296875, -1.5, -0.6640625, -0.7578125, -0.404296875, -1.8125, 0.6015625, 0.1904296875, -0.625, 0.173828125, -0.71484375, -2.5625, 1.2265625, 1.6796875, -2.53125, 1.6640625, 2.25, -2.515625, -0.11181640625, -0.47265625, 0.3515625, 0.146484375, -0.92578125, -1.078125, 1.0625, 0.578125, -0.291015625, -1.8671875, 1.09375, -1.453125, -1.1796875, 0.375, 0.62109375, 2.90625, -0.439453125, 0.1845703125, 0.7890625, -0.70703125, -0.365234375, -0.9296875, 1.1953125, 0.375, 0.5390625, -0.2138671875, -0.6484375, 2.703125, 1.015625, -0.2451171875, 0.953125, -0.12451171875, 0.75, 1.0625, -0.6171875, -1.5, 1.0546875, 0.9140625, -0.0693359375, -0.4296875, 1.0546875, -0.6171875, -2.0625, 0.78125, 0.6953125, -3.375, -0.9453125, -0.37890625, 1.7265625, -1.0234375, 0.1328125, 0.06298828125, 2.078125, -0.453125, -9.25, -0.283203125, 1.328125, -0.375, -0.55078125, 0.9140625, -0.326171875, 1.1484375, -0.6796875, 0.91015625, -1.3671875, 0.318359375, -0.72265625, -0.326171875, -0.5, 0.76171875, -1.6015625, -0.63671875, -1.421875, 1.4375, 0.93359375, -0.01904296875, -0.267578125, 0.66015625, 0.98828125, 0.953125, -0.703125, -0.380859375, 0.65234375, -3.546875, -0.85546875, -0.96875, 2.484375, 1.0234375, -0.6015625, -1.84375, -0.228515625, -1.1796875, -0.392578125, 0.8359375, 0.107421875, 2.671875, 0.224609375, -0.0169677734375, 1.40625, -2.015625, -0.80078125, 0.75390625, 1.109375, 2.125, 1.578125, -1.1015625, 1.953125, 0.44921875, 0.80078125, 2.3125, 0.45703125, 0.310546875, 4.125, -1.1015625, -0.8203125, -0.75, -1.4453125, 1.109375, 0.60546875, -0.1953125, 0.66015625, 1.5859375, 0.8515625, 0.23828125, -0.66015625, 2.84375, -0.1650390625, 0.65625, -0.08935546875, -0.328125, -1.5234375, 0.99609375, 1.4375, 0.78515625, -1.375, -0.66796875, -1.46875, 0.890625, -0.69140625, 0.65234375, -1.8671875, 0.640625, -0.86328125, 2.171875, -2.0625, 1.4375, 1.0, 1.5234375, -2.28125, 2.328125, 1.40625, -0.26953125, -1.6171875, 1.2421875, -0.10595703125, -0.5234375, 1.1953125, -0.263671875, -0.46484375, -1.1015625, 0.84765625, 0.6484375, -0.70703125, 0.1025390625, 0.8515625, -0.33984375, 2.921875, -0.435546875, 0.427734375, 3.421875, 1.265625, 1.0078125, 0.330078125, -0.404296875, -0.2314453125, 1.828125, 0.640625, -0.78125, -2.046875, -3.046875, 0.1357421875, -1.1171875, -0.83203125, -1.0859375, -1.171875, 1.1875, -0.318359375, 1.0546875, 0.1259765625, -0.373046875, -0.56640625, -0.1455078125, 2.59375, 1.25, 0.84375, -0.6484375, 1.421875, -0.796875, -2.265625, 2.734375, 1.140625, 0.353515625, 1.15625, -0.875, -0.490234375, 0.66015625, -0.92578125, -0.263671875, 0.78515625, 0.099609375, 0.24609375, 0.90234375, 2.125, -1.2734375, 0.18359375, -1.8984375, -1.1953125, 1.90625, -0.2021484375, 1.9453125, 2.328125, 1.15625, 0.4140625, -0.1640625, -0.75, -0.62890625, -2.34375, -1.59375, -0.7734375, -1.53125, -0.056396484375, -0.3671875, 1.1953125, 1.4296875, 3.234375, 0.7421875, -0.466796875, -0.1318359375, -0.06591796875, -0.73828125, -1.0703125, -2.34375, 0.5234375, 0.9453125, -0.4921875, -1.9453125, -0.95703125, -0.0106201171875, 0.78125, 0.953125, -0.21484375, 1.640625, -0.87109375, 1.765625, -1.921875, -0.28125, -0.765625, -0.38671875, -1.8828125, 0.333984375, -1.671875, 1.3671875, 0.7734375, 1.484375, -1.3984375, 2.1875, -0.875, 0.6328125, 0.43359375, 0.55859375, -1.15625, -0.73046875, 0.5625, 1.546875, 0.2451171875, -1.640625, 0.86328125, 1.5, -0.80078125, -1.7109375, 2.671875, -0.486328125, -0.88671875, -0.2041015625, -1.9375, -0.0201416015625, 0.9921875, -2.5625, 1.7578125, 1.796875, 0.0986328125, 1.875, 0.66796875, -1.140625, 2.46875, -0.8125, -0.7109375, 1.328125, -1.28125, 0.53125, -0.99609375, -1.65625, 1.296875, -1.0078125, -1.578125, -0.75, 3.40625, -1.609375, 1.40625, 2.21875, -1.1953125, 0.9921875, -2.75, -2.28125, 1.25, 0.5078125, -2.03125, -1.4296875, 0.87109375, 0.87890625, -0.80859375, -1.8359375, -0.76171875, 0.09326171875, 0.53125, 1.390625, -0.52734375, -0.92578125, -0.26171875, -1.1953125, 1.4453125, -0.10888671875, -0.1123046875, 0.1171875, 3.1875, 1.15625, 2.28125, -1.84375, 0.5078125, 0.37109375, 1.265625, -0.8359375, 1.2421875, 1.1875, 0.333984375, 0.94140625, -0.396484375, -1.15625, -0.0235595703125, 0.26953125, 0.65234375, 0.5703125, 0.228515625, -0.7734375, -0.671875, -1.1640625, 1.1640625, 1.8984375, -0.314453125, 1.0078125, 0.08447265625, 1.1171875, -0.474609375, -0.14453125, -2.78125, -0.482421875, 1.5234375, -0.318359375, 1.5, -0.1904296875, -0.36328125, -0.6328125, -0.60546875, -0.011474609375, 0.57421875, 0.82421875, 0.244140625, 0.87890625, 1.2890625, 0.474609375, 0.2158203125, -0.482421875, 0.26953125, 1.1328125, -1.4609375, 1.5546875, -0.37890625, 0.408203125, 1.015625, 0.3046875, 1.671875, 0.318359375, -1.0234375, 1.28125, 0.11181640625, 3.140625, -0.6328125, -2.484375, -0.7734375, 1.6875, 1.09375, 0.115234375, 1.5390625, 0.057861328125, 0.055908203125, 0.2255859375, -0.6796875, 0.458984375, 2.640625, 0.1884765625, -0.2353515625, -0.1474609375, -1.1953125, -1.671875, 0.337890625, -1.4921875, 1.1328125, -0.84375, 0.4765625, -1.078125, 2.015625, -0.91015625, -0.890625, 0.416015625, -0.359375, 1.3984375, 2.484375, -0.3671875, -2.34375, 1.1328125, 0.212890625, 2.46875, 0.75390625, 0.490234375, 2.265625, 1.0625, -1.546875, 0.44921875, -0.345703125, 1.0859375, -0.9921875, 0.734375, 0.94921875, -0.84375, 0.056884765625, 0.78515625, 0.5859375, -0.1103515625, -0.88671875, 0.80078125, 0.08447265625, 0.81640625, -1.4609375, -0.7578125, 1.40625, 0.10009765625, -2.203125, 0.228515625, 1.578125, 0.05859375, 2.328125, 1.71875, 1.375, 0.244140625, 0.28515625, -0.255859375, -1.4453125, -1.796875, -1.3203125, -0.1884765625, -0.6875, 2.78125, -0.055419921875, 0.03564453125, -1.890625, 2.28125, -2.140625, 0.2138671875, 1.0390625, -0.04833984375, -1.1484375, 0.71484375, -1.03125, -1.421875, -2.125, 0.54296875, 1.1171875, 2.265625, 2.390625, 1.7421875, 3.109375, 0.21875, 0.046630859375, 1.65625, 1.21875, -0.61328125, 1.8203125, -1.7734375, 2.421875, -1.3046875, -0.1591796875, 0.2216796875, 0.09033203125, -2.078125, -1.1171875, -0.8515625, 1.8046875, -1.8203125, -0.58984375, 1.46875, -2.171875, -0.6953125, 1.5859375, 0.447265625, -0.294921875, -1.296875, -2.734375, 0.53125, -0.8671875, -0.1552734375, 1.1484375, -0.2353515625, -1.0390625, -0.0625, -1.3046875, 0.4140625, 1.5, 0.40234375, 1.15625, -1.0625, 1.0703125, 2.546875, -0.0233154296875, 0.73828125, -0.458984375, 1.078125, 0.44140625, -0.0576171875, 2.0625, -0.451171875, -0.6640625, -1.390625, -0.205078125, 0.138671875, -1.8046875, 0.65625, 1.328125, -0.1025390625, 3.0625, 1.7109375, -1.75, 0.12353515625, -1.109375, 1.8046875, 0.4765625, 0.58203125, -0.037353515625, -0.296875, -0.72265625, -0.1533203125, 2.390625, -0.3359375, -1.4765625, -0.98046875, 0.578125, 1.1328125, -0.98828125, 0.81640625, 3.4375, 2.421875, 1.359375, -0.64453125, 0.8515625, -1.2265625, 0.0927734375, 1.546875, 2.3125, 0.224609375, -0.89453125, 0.8828125, -0.65234375, 0.197265625, 2.5625, 0.427734375, -1.8984375, -1.296875, 0.5625, -0.90234375, -1.4296875, -3.328125, 1.234375, 0.94921875, -0.1279296875, 0.435546875, 0.283203125, -2.859375, 0.97265625, 1.125, 0.2890625, 0.0732421875, -2.453125, -0.9375, 2.5625, 0.01263427734375, -1.1328125, -6.0, 0.1875, 1.0078125, -1.4921875, -0.21875, -1.953125, 1.1953125, 0.333984375, 0.80078125, 0.94921875, 1.3359375, 1.671875, 1.109375, -1.828125, 0.62890625, -11.25, 0.08154296875, 0.047119140625, 0.44921875, -0.48828125, 2.296875, 0.490234375, 1.15625, 1.484375, 0.51171875, 0.09423828125, -1.34375, 0.6328125, 0.5703125, 0.859375, 0.322265625, -1.0625, -0.421875, 0.146484375, 0.29296875, 0.765625, 0.98828125, -0.82421875, -0.2490234375, -1.4296875, -0.2734375, 1.6640625, -1.03125, 2.265625, 1.78125, 2.359375, 0.7109375, 2.015625, 1.28125, 0.67578125, 0.67578125, -1.9375, -0.24609375, 1.6015625, 1.3359375, -1.078125, 2.5, 0.6171875, 0.3984375, -0.51953125, 2.28125, 0.56640625, 1.7109375, -1.109375, -0.33984375, 0.486328125, -1.4921875, -0.07568359375, 0.81640625, -0.10546875, 0.01397705078125, 0.3203125, 0.384765625, -0.54296875, -0.1767578125, -0.09912109375, -0.8671875, 0.26171875, -0.60546875, -0.349609375, -0.1416015625, 0.6171875, 0.74609375, -0.81640625, -2.234375, 0.78125, 0.54296875, 0.71484375, 0.28515625, 0.173828125, -0.11669921875, 0.8984375, 0.451171875, -0.125, 0.05615234375, 0.091796875, 2.4375, 1.6640625, 1.640625, -2.328125, 0.96875, 0.84375, 6.4375, 0.51171875, 0.703125, 2.40625, 0.59765625, 0.59375, -0.65625, -1.4921875, 3.203125, -0.337890625, 2.390625, 0.4921875, 1.0234375, 0.474609375, 0.4609375, -1.6015625, 1.625, -1.171875, -0.1640625, -1.3203125, -1.40625, -0.8125, 0.421875, 0.65234375, 0.9140625, -0.93359375, 1.6015625, 1.5703125, -0.5390625, -0.1611328125, -0.6640625, -0.12109375, 0.1083984375, 1.6328125, 1.234375, 0.54296875, 0.06591796875, -1.09375, 0.515625, -0.7578125, -2.03125, -1.109375, 2.921875, 1.8359375, 2.328125, -1.453125, 1.234375, 1.2109375, -0.0155029296875, 0.1005859375, 0.71875, -1.265625, 0.064453125, 0.9453125, 0.146484375, -1.3828125, 1.265625, -0.5703125, 1.3203125, 0.8828125, -0.44140625, -0.5625, -1.578125, 3.3125, -0.234375, 1.0546875, 0.56640625, 1.328125, -1.5546875, -0.75390625, -0.84375, 1.0, 0.48828125, -0.0732421875, -0.87890625, 1.3828125, -1.96875, -1.1796875, -0.7734375, 0.41796875, 2.71875, -0.8671875, 1.296875, 0.51171875, 1.3828125, -2.203125, -0.82421875, -2.125, 0.057861328125, -0.8828125, -0.2470703125, 0.62890625, 1.5234375, -0.13671875, 1.359375, -1.390625, -0.2373046875, -0.5703125, -0.82421875, 0.380859375, -0.002716064453125, -0.9609375, 2.28125, 0.59375, -0.8359375, 0.392578125, 0.470703125, 1.484375, -1.9375, -1.5078125, -2.171875, -0.578125, 1.0390625, -0.26953125, 0.58203125, 1.5625, -0.84765625, -0.1162109375, 0.07177734375, 3.40625, -0.94921875, -0.36328125, -0.63671875, 2.0, -0.4921875, -0.99609375, 0.1591796875, 0.49609375, -0.462890625, -0.494140625, -0.80078125, 1.171875, 0.328125, 3.90625, 0.6875, -2.609375, -1.03125, 0.734375, 0.59375, -0.6875, -2.125, 0.8671875, 0.3828125, 1.75, 1.5, 0.66796875, -2.25, 0.51953125, 2.109375, 0.1484375, 0.984375, 0.08203125, 0.462890625, -1.90625, -0.0302734375, 0.8359375, 0.546875, -1.4296875, 0.1513671875, 2.15625, 1.4921875, -0.0849609375, 0.72265625, 0.29296875, -0.890625, -0.23046875, -0.38671875, -1.4140625, -0.11376953125, -0.271484375, 0.69140625, 1.0234375, -0.423828125, 1.2734375, 1.7578125, -1.1953125, -0.06298828125, -2.265625, 0.07080078125, 0.482421875, 1.265625, 0.55859375, 1.5390625, -0.4765625, 1.5078125, -0.1025390625, 0.8984375, -0.6640625, 1.2421875, -1.6015625, -0.8515625, -1.4453125, 0.017822265625, -1.7421875, 2.484375, -1.5078125, 2.03125, 1.0546875, 0.4921875, -0.65234375, 0.0185546875, 0.1181640625, -0.66796875, -3.125, -1.5234375, -0.498046875, 2.0625, 0.4375, -0.2314453125, 0.609375, 0.37890625, -1.6484375, -1.6640625, 1.8203125, 0.64453125, 1.421875, 1.34375, -0.365234375, 0.41015625, 0.73046875, -1.6640625, -0.23046875, 0.486328125, -0.7890625, -2.515625, -1.6328125, -0.68359375, 0.98828125, -1.8828125, -0.162109375, 1.2890625, -1.9140625, 0.28515625, 0.55859375, 0.57421875, 1.6484375, -0.173828125, -0.419921875, 0.5234375, -0.000690460205078125, -0.220703125, -0.146484375, 1.34375, 0.83203125, 0.4453125, -0.4375, 0.9609375, 1.03125, -1.3203125, -1.9921875, 2.734375, 4.15625, 1.484375, -1.1640625, -0.98046875, 0.95703125, 0.84375, -1.2734375, 0.99609375, 0.040283203125, 0.97265625, 0.671875, -0.06689453125, -0.10595703125, 2.359375, -1.859375, 0.62109375, 0.251953125, -3.828125, 3.265625, 0.77734375, -0.828125, -1.453125, -0.44921875, 2.15625, 0.035888671875, 0.1044921875, 0.474609375, 1.2578125, -0.8671875, 1.328125, 0.54296875, 1.46875, 1.4609375, 1.625, -1.953125, -0.4140625, 0.58203125, -0.5703125, -0.5390625, -0.89453125, -1.1796875, 2.6875, 1.3515625, 0.33203125, 0.875, 0.8828125, 1.65625, -0.65625, 4.0625, -1.015625, -0.640625, -1.125, 2.875, 0.2470703125, -0.890625, -1.6953125, 1.421875, -0.404296875, 1.71875, -0.171875, 1.328125, -0.12109375, -2.453125, -0.55078125, 0.9765625, 1.171875, 0.55859375, 0.1865234375, -0.408203125, -0.353515625, -0.70703125, -0.5625, 0.7109375, 1.046875, 0.59375, -0.443359375, -0.1904296875, -0.265625, 1.875, -0.197265625, 2.171875, -0.6875, 0.1826171875, 0.77734375, -0.578125, 1.8046875, 0.11669921875, 1.4921875, -2.328125, -0.482421875, 0.96484375, 0.9765625, -0.00830078125, 2.828125, -1.7578125, 0.8984375, 0.75390625, 0.44921875, -0.1357421875, 0.1689453125, 0.8046875, 2.078125, 1.09375, 2.71875, -0.921875, 0.7109375, -1.2734375, -0.5625, 3.171875, -0.8125, -0.63671875, -1.5, -1.1875, -0.57421875, 0.90625, -0.435546875, 0.2333984375, 0.4765625, 0.62890625, -0.416015625, -1.375, 0.69921875, 1.46875, -1.8125, 2.84375, 0.490234375, -1.4375, -0.5859375, -0.228515625, 1.1484375, 0.2197265625, 0.05322265625, -0.341796875, -0.0439453125, 2.0, -2.703125, 0.62890625, -0.609375, -1.3984375, 0.97265625, -0.04150390625, -2.203125, -0.2216796875, 0.8359375, 1.53125, -0.5703125, -0.2119140625, 0.8671875, 0.64453125, -0.54296875, 2.15625, -1.109375, 0.318359375, 0.76171875, 1.5859375, -0.8515625, -1.140625, 0.53515625, 0.1650390625, 0.87890625, 2.703125, -0.005584716796875, 4.28125, 0.79296875, -1.640625, -1.015625, 0.33203125, 1.0546875, 1.0625, -0.796875, -0.91796875, 1.0859375, 0.74609375, 0.9375, 0.1826171875, -0.423828125, 1.40625, -0.6328125, 0.33984375, -2.34375, -1.765625, -1.7578125, 1.8671875, 0.98828125, -0.87109375, 1.84375, 0.43359375, 0.1533203125, 0.59765625, -1.046875, -0.5703125, 0.27734375, 0.0059814453125, -0.361328125, 1.3359375, -2.375, -0.2451171875, -1.7421875, 0.5625, 0.58984375, -1.171875, -0.7734375, -0.7890625, -0.0089111328125, 0.7265625, -2.375, 0.75, -0.53515625, 0.412109375, -0.7265625, -0.76171875, -0.328125, 0.92578125, 1.6171875, -0.546875, 2.625, -0.44140625, 0.9609375, -1.3046875, 0.81640625, 0.154296875, 2.5, -0.99609375, 2.234375, -0.95703125, 0.8515625, 0.2109375, 1.0546875, 0.2158203125, 3.390625, -0.396484375, 1.84375, -2.0, 0.4375, -0.6875, -2.609375, 1.5859375, -0.296875, -0.72265625, -0.4140625, 0.85546875, -0.81640625, 0.08935546875, 0.76171875, 0.08349609375, 0.12255859375, -2.953125, -1.96875, 1.6484375, -0.353515625, 0.94921875, 2.234375, -0.72265625, 2.78125, 0.458984375, -1.578125, -0.71875, 2.09375, 1.0390625, 0.6875, 1.078125, 0.193359375, -0.50390625, 0.890625, -0.6953125, -1.2265625, -0.234375, 0.12255859375, -0.55078125, -0.578125, -0.90625, -1.078125, 0.75390625, 0.85546875, -3.109375, -3.53125, -2.546875, -0.6640625, -0.3515625, 2.859375, 0.89453125, 1.7890625, -1.2890625, 0.77734375, -0.62109375, -1.4140625, -0.63671875, -0.416015625, -5.46875, -0.6640625, 0.890625, 1.453125, 1.9765625, 0.392578125, 0.84765625, -0.9453125, 0.81640625, 1.7734375, -0.78125, -0.48828125, 1.125, 0.64453125, -0.7734375, -2.203125, -0.89453125, -0.9921875, -0.036376953125, 0.447265625, -0.5234375, 1.46875, 0.25390625, 0.640625, -0.298828125, 1.9609375, -0.1669921875, 1.828125, 0.2578125, 2.421875, -0.65625, -1.296875, -0.59375, -1.78125, -0.7890625, 1.75, -0.07421875, -2.28125, -0.349609375, 0.57421875, 0.3125, 1.109375, 1.125, 0.0439453125, 2.28125, 1.7734375, 2.015625, 0.21875, -2.484375, 2.609375, -1.234375, -1.4375, -2.390625, -0.4609375, 1.734375, -0.78515625, 0.330078125, -1.7109375, -0.6171875, 0.2109375, 0.46875, -1.6796875, 0.423828125, 1.8359375, -0.37890625, -1.1484375, -0.859375, -0.875, -1.8359375, 1.75, 1.2578125, 0.39453125, 0.037841796875, 0.86328125, 1.015625, 1.8125, 0.94140625, 0.234375, 1.4140625, 0.89453125, -0.5546875, -1.5, 0.486328125, 1.3046875, 1.671875, 2.0, 0.380859375, -0.318359375, -1.2109375, -1.609375, 1.1015625, 1.515625, 2.25, -1.140625, 1.734375, -0.349609375, 0.220703125, -1.875, 1.03125, 3.125, -1.046875, 0.2578125, -2.46875, -0.0223388671875, -0.06103515625, 0.94921875, -0.00069427490234375, 0.84765625, -2.078125, 0.39453125, -0.322265625, -0.43359375, 0.9375, 1.1640625, -1.1875, -1.0703125, 0.25, 1.4296875, -0.72265625, -1.7109375, 0.322265625, 0.51953125, -0.419921875, 2.203125, -0.421875, -0.451171875, -1.546875, 1.296875, 1.5390625, -0.087890625, -0.46484375, 1.1015625, 0.53515625, 0.59765625, -1.4765625, -0.2060546875, 1.09375, -0.6484375, 0.60546875, -0.326171875, -1.0703125, -2.015625, 0.21875, 0.87890625, -1.9296875, 0.6796875, 0.6015625, 0.97265625, 0.96875, -0.52734375, 2.109375, 1.4921875, 0.9296875, 1.3671875, 1.4921875, -0.7421875, -1.1796875, -2.125, -1.90625, 0.79296875, 2.046875, -1.5234375, -0.84375, -1.109375, 1.8828125, -0.47265625, -0.287109375, 0.1728515625, 0.030517578125, 1.0234375, 1.2734375, 1.03125, 1.890625, -1.828125, 0.76171875, -0.173828125, -2.296875, 0.70703125, -0.734375, 0.41796875, 1.90625, 2.78125, -0.1748046875, -0.45703125, -2.546875, -0.64453125, 0.017578125, 1.7109375, -2.140625, 0.0289306640625, -0.11572265625, -0.55078125, 2.5, 0.75, -0.609375, -1.203125, -0.72265625, -0.6328125, -0.703125, -0.57421875, 0.4375, -0.43359375, -1.0078125, -1.015625, 1.8515625, 1.1640625, 1.4453125, 0.515625, -0.1357421875, 0.3359375, 0.08203125, -0.29296875, 2.03125, -1.015625, 2.09375, 0.6875, 0.228515625, -1.703125, 0.67578125, 0.396484375, -1.4140625, -2.171875, 0.458984375, 0.62109375, 1.65625, 1.515625, -0.388671875, 0.228515625, -0.3125, 1.2109375, 0.68359375, -1.40625, 1.3359375, 0.330078125, 0.359375, 0.7734375, -0.52734375, 1.59375, 2.171875, 1.9921875, 0.275390625, 0.2109375, -2.421875, 0.9140625, 1.9453125, -0.515625, 0.87109375, -0.322265625, 1.5234375, -0.97265625, 1.703125, -0.3515625, 0.76171875, -0.142578125, -1.1640625, -0.07763671875, -0.51953125, 2.03125, 0.6796875, 0.55859375, 0.416015625, 0.8203125, -0.8046875, 0.80078125, -0.341796875, -1.109375, 0.0810546875, -0.24609375, -1.4921875, 0.86328125, 0.470703125, 0.53515625, -0.07373046875, -0.51171875, -0.053466796875, -1.8359375, -0.2734375, 0.482421875, -0.201171875, -0.41015625, 0.74609375, 0.53515625, -1.7578125, -1.9609375, 1.875, -0.470703125, 0.330078125, 2.28125, 1.9921875, -1.90625, 0.384765625, 1.4140625, 1.828125, -0.064453125, -0.412109375, 1.9921875, -1.8203125, 0.875, 0.240234375, 1.2421875, -0.291015625, -0.8046875, -2.71875, -0.34375, -0.28515625, -0.73046875, 1.1015625, 0.2041015625, 2.375, -1.2890625, -0.69921875, 0.6796875, 0.419921875, 0.7265625, -0.427734375, 0.310546875, 1.1640625, -0.150390625, -1.5546875, 2.328125, -2.359375, 0.5078125, -0.171875, 0.8828125, 1.203125, -2.453125, 1.0546875, -1.9453125, 0.6328125, -1.6875, 0.4453125, 0.123046875, -1.5390625, -1.8125, -0.91015625, 0.3359375, 0.37890625, 0.32421875, 2.140625, 0.9453125, 1.953125, -0.017822265625, -0.83984375, -0.71484375, 2.0, 3.1875, 5.03125, -0.474609375, -0.96484375, 3.015625, -0.125, -0.40625, -1.7421875, -1.0, 0.65625, -0.921875, 0.10693359375, 1.1875, 2.046875, -0.337890625, 0.6796875, 0.3359375, -1.8671875, 2.6875, -0.6171875, 0.6328125, 0.04443359375, -1.0078125, -0.02099609375, 1.328125, -1.6171875, 0.9921875, 0.56640625, -0.9609375, 0.62109375, -1.4765625, -0.58984375, -0.8984375, -0.83203125, -1.5234375, -1.1953125, 0.6640625, 0.6484375, 1.6875, 2.140625, -0.8359375, -1.78125, 1.6328125, -2.0, 1.109375, -0.92578125, -0.375, 0.74609375, 0.044921875, -0.1845703125, 0.15625, 1.8125, 0.71875, 0.55078125, 1.03125, 0.3515625, -1.171875, 0.11865234375, 2.046875, -2.96875, -0.02685546875, -0.765625, 0.16015625, -0.63671875, -1.3515625, 0.3359375, 0.0189208984375, -0.458984375, 0.5234375, 1.59375, -0.48828125, -1.2578125, 0.4921875, 1.1015625, 0.73828125, 3.015625, 0.87109375, -0.009765625, -2.1875, -0.498046875, 0.11279296875, -0.79296875, -2.8125, 0.5703125, 0.11083984375, -0.62890625, -1.390625, 0.671875, 0.478515625, -1.71875, 1.453125, 0.98046875, -1.109375, -0.3515625, -1.203125, -0.05810546875, 1.2109375, -1.5546875, -0.8125, -0.73828125, -1.890625, 0.310546875, 0.0091552734375, -0.4765625, -2.296875, 1.0234375, 1.6171875, -0.96875, -0.69921875, -0.0810546875, -0.310546875, -0.8828125, -1.7421875, -0.9609375, -0.376953125, -0.6796875, 1.328125, -1.3203125, -2.34375, 1.5625, 0.97265625, 0.52734375, 2.625, -0.31640625, 1.046875, -1.5078125, 1.4140625, 0.376953125, 0.20703125, 0.154296875, 0.2197265625, 1.53125, -1.984375, 0.296875, -0.1357421875, -1.09375, 1.515625, -1.03125, 1.0390625, -0.1962890625, -1.0703125, 0.859375, 0.32421875, 0.2041015625, 1.0078125, 0.193359375, -0.09033203125, 0.169921875, 1.1640625, 0.0303955078125, 0.85546875, -1.4375, 0.255859375, -0.5078125, 0.41796875, -1.5625, 0.640625, 1.40625, -0.080078125, -3.5, 1.390625, 0.111328125, 0.90234375, -1.0078125, -0.376953125, -1.5, 1.0390625, 1.5859375, 1.3359375, -1.2578125, 0.302734375, -0.81640625, 11.25, -0.578125, -1.2578125, -2.078125, -0.62890625, 0.7109375, -0.2041015625, 0.92578125, -0.376953125, -0.046142578125, -1.046875, 0.05615234375, -0.9921875, 0.40625, -0.546875, 0.6640625, 1.6796875, -0.55859375, -0.9609375, 0.4765625, 0.0888671875, -1.421875, -0.91796875, -1.046875, 1.28125, 1.8828125, 1.15625, -0.75390625, 0.54296875, 0.482421875, 0.2001953125, 0.287109375, -1.3828125, 1.5703125, 2.171875, -1.84375, -1.2109375, -0.17578125, -0.044921875, -0.455078125, 0.79296875, 0.2373046875, -0.158203125, -1.6875, 0.22265625, -0.1015625, -0.1845703125, -0.56640625, -1.6640625, -1.84375, -1.046875, 0.42578125, -0.2373046875, 0.65625, 0.1015625, 0.294921875, 0.07470703125, -0.2294921875, -2.015625, -14.5625, -1.5859375, -1.8671875, -0.90625, -0.984375, 1.7109375, 0.01239013671875, -0.6484375, -1.5859375, -0.28515625, -1.09375, 0.62109375, -0.408203125, -2.65625, -0.7421875, 1.71875, 2.109375, 0.19921875, -1.28125, 1.953125, -0.6640625, 0.267578125, -0.302734375, 0.16796875, -1.1875, 0.2197265625, 1.234375, -0.16796875, 0.19140625, 0.224609375, -0.1591796875, 3.046875, -0.66796875, -0.53125, 0.81640625, 0.275390625, 0.263671875, -0.94140625, 1.9765625, -2.125, 0.78125, -0.39453125, 1.65625, -0.70703125, -1.21875, 1.6171875, -1.34375, -0.8984375, -1.421875, 1.4140625, 0.0810546875, 0.7578125, 0.1826171875, -0.66015625, 0.65234375, -1.0, 0.62890625, 1.0078125, -2.015625, 0.578125, 1.5, -1.8359375, -1.0703125, -0.56640625, -0.333984375, 0.7421875, 0.28515625, -0.42578125, -1.0], index=0, object='embedding')], model='doubao-embedding-large-text-240915', object='list', usage=Usage(prompt_tokens=11, total_tokens=11), created=1747895135, id='02174789513514716b977401f4df41f54664316aeb6668e295868')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "返回的embedding类型为：list\n"
     ]
    }
   ],
   "source": [
    "print(f'返回的embedding类型为：{response.object}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding长度为：4096\n",
      "embedding（前10）为：[-0.70703125, 2.671875, 0.95703125, -3.484375, -0.421875, -4.03125, 1.4765625, 3.0625, 0.4609375, 0.80859375]\n"
     ]
    }
   ],
   "source": [
    "print(f'embedding长度为：{len(response.data[0].embedding)}')\n",
    "print(f'embedding（前10）为：{response.data[0].embedding[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次embedding model为：doubao-embedding-large-text-240915\n",
      "本次token使用情况为：Usage(prompt_tokens=11, total_tokens=11)\n"
     ]
    }
   ],
   "source": [
    "print(f'本次embedding model为：{response.model}')\n",
    "print(f'本次token使用情况为：{response.usage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 pdf数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf\")\n",
    "\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>， 该 PDF 一共包含 196 页\n"
     ]
    }
   ],
   "source": [
    "print(f\"载入后的变量类型为：{type(pdf_pages)}，\",  f\"该 PDF 一共包含 {len(pdf_pages)} 页\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20230303170709-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "------\n",
      "查看该文档的内容:\n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、\n",
      "spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_page = pdf_pages[1]\n",
    "print(f\"每一个元素的类型：{type(pdf_page)}.\", \n",
    "    f\"该文档的描述性数据：{pdf_page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{pdf_page.page_content}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 md数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(\"../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md\")\n",
    "md_pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>， 该 Markdown 一共包含 1 页\n"
     ]
    }
   ],
   "source": [
    "print(f\"载入后的变量类型为：{type(md_pages)}，\",  f\"该 Markdown 一共包含 {len(md_pages)} 页\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Larg\n"
     ]
    }
   ],
   "source": [
    "md_page = md_pages[0]\n",
    "print(f\"每一个元素的类型：{type(md_page)}.\", \n",
    "    f\"该文档的描述性数据：{md_page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{md_page.page_content[0:][:200]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 匹配\"非中文字符+换行符+非中文字符\"的模式，并将其中的换行符替换为空字符串\n",
    "import re\n",
    "pattern = re.compile(r'[^\\u4e00-\\u9fff](\\n)[^\\u4e00-\\u9fff]', re.DOTALL)\n",
    "pdf_page.page_content = re.sub(pattern, lambda match: match.group(0).replace('\\n', ''), pdf_page.page_content)\n",
    "print(pdf_page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\n",
      "最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去除多余的字符\n",
    "pdf_page.page_content = pdf_page.page_content.replace('•', '')\n",
    "pdf_page.page_content = pdf_page.page_content.replace(' ', '')\n",
    "print(pdf_page.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一章 简介\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。\n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。\n",
      "因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。\n",
      "如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。\n"
     ]
    }
   ],
   "source": [
    "# 去除连续的换行\n",
    "md_page.page_content = md_page.page_content.replace('\\n\\n', '\\n')\n",
    "print(md_page.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 文档分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "489 ----------------------------------------------------------------------------------------------------\n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "489 ----------------------------------------------------------------------------------------------------\n",
      "有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们GitHub的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\n",
      "最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "24 ----------------------------------------------------------------------------------------------------\n",
      "编委会\n",
      "主编：Sm1les、archwalker\n"
     ]
    }
   ],
   "source": [
    "# 使用按字符串递归分割文本的分割器\n",
    "# 分割优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 单段文本长度\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 相邻文本重合长度\n",
    "OVERLAP_SIZE = 50\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "# 分割文本\n",
    "split_text = text_splitter.split_text(pdf_page.page_content[:1000])\n",
    "print(len(split_text))\n",
    "for t in split_text:\n",
    "    print(len(t), \"-\"*100)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 观察上述的文本会发现，并没有实现50个字符的重叠，这是由分割器决定的，该分割器会优先按自然结构进行划分（如换分、分段等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：711\n"
     ]
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents(pdf_pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的字符数（可以用来大致评估 token 数）：305816\n"
     ]
    }
   ],
   "source": [
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 搭建并使用向量数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 加载知识库数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_base/knowledge_db/prompt_engineering/6. 文本转换 Transforming.md', '../data_base/knowledge_db/prompt_engineering/4. 文本概括 Summarizing.md', '../data_base/knowledge_db/prompt_engineering/5. 推断 Inferring.md']\n"
     ]
    }
   ],
   "source": [
    "# 递归获取所有知识库将要使用的文件路径\n",
    "file_paths = []\n",
    "folder_path = \"../data_base/knowledge_db\"\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.startswith(\".\"):\n",
    "            continue\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# 构建数据加载器\n",
    "loaders = []\n",
    "for file_path in file_paths:\n",
    "    file_type = file_path.split(\".\")[-1]\n",
    "    if file_type == \"pdf\":\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == \"md\":\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))\n",
    "\n",
    "# 加载数据\n",
    "texts = []\n",
    "for loader in loaders:\n",
    "    texts.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../data_base/knowledge_db/prompt_engineering/4. 文本概括 Summarizing.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第四章 文本概括\n",
      "\n",
      "在繁忙的信息时代，小明是一名热心的开发者，面临着海量的文本信息处理的挑战。他需要通过研究无数的文献资料来为他的项目找到关键的信息，但是时间却远远不够。在他焦头烂额之际，他发现了大型语言模型（LLM）的文本摘要功能。\n",
      "\n",
      "这个功能对小明来说如同灯塔一样，照亮了他处理信息海洋的道路。LLM 的强大能力在于它可以将复杂的文本信息简化，提炼出关键的观点，这对于他来说无疑是巨大的帮助。他不再需要花费大量的时间去阅读所有的文档，只需要用 LLM 将它们概括，就可以快速获取到他所需要的信息。\n",
      "\n",
      "通过编程调用 AP I接口，小明成功实现了这个文本摘要的功能。他感叹道：“这简直就像一道魔法，将无尽的信息海洋变成了清晰的信息源泉。”小明的经历，展现了LLM文本摘要功能的巨大优势：节省时间，提高效率，以及精准获取信息。这就是我们本章要介绍的内容，让我们一起来探索如何利用编程和调用API接口，掌握这个强大的工具。\n",
      "\n",
      "一、单一文本概括\n",
      "\n",
      "以商品评论的总结任务为例：对于电商平台来说，网站上往往存在着海量的商品评论，这些评论反映了所有客户的想法。如果我们拥有一个工具去概括这些海量、冗长的评论，便能够快速地浏览更多评论，洞悉客户的偏好，从而指导平台与商家提供更优质的服务。\n",
      "\n",
      "接下来我们提供一段在线商品评价作为示例，可能来自于一个在线购物平台，例如亚马逊、淘宝、京东等。评价者为一款熊猫公仔进行了点评，评价内容包括商品的质量、大小、价格和物流速度等因素，以及他的女儿对该商品的喜爱程度。\n",
      "\n",
      "python prod_review = \"\"\" 这个熊猫公仔是我给女儿的生日礼物，她很喜欢，去哪都带着。 公仔很软，超级可爱，面部表情也很和善。但是相比于价钱来说， 它有点小，我感觉在别的地方用同样的价钱能买到更大的。 快递比预期提前了一天到货，所以在送给女儿之前，我自己玩了会。 \"\"\"\n",
      "\n",
      "1.1 限制输出文本长度\n",
      "\n",
      "我们首先尝试将文本的长度限制在30个字以内。\n",
      "\n",
      "```python from tool import get_completion\n",
      "\n",
      "prompt = f\"\"\" 您的任务是从电子商务网站上生成一个产品评论的简短摘要。\n",
      "\n",
      "请对三个反引号之间的评论文本进行概括，最多30个字。\n",
      "\n",
      "评论: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "熊猫公仔软可爱，女儿喜欢，但有点小。快递提前一天到货。\n",
      "\n",
      "我们可以看到语言模型给了我们一个符合要求的结果。\n",
      "\n",
      "注意：在上一节中我们提到了语言模型在计算和判断文本长度时依赖于分词器，而分词器在字符统计方面不具备完美精度。\n",
      "\n",
      "1.2 设置关键角度侧重\n",
      "\n",
      "在某些情况下，我们会针对不同的业务场景对文本的侧重会有所不同。例如，在商品评论文本中，物流部门可能更专注于运输的时效性，商家则更关注价格和商品质量，而平台则更看重整体的用户体验。\n",
      "\n",
      "我们可以通过增强输入提示（Prompt），来强调我们对某一特定视角的重视。\n",
      "\n",
      "1.2.1 侧重于快递服务\n",
      "\n",
      "```python prompt = f\"\"\" 您的任务是从电子商务网站上生成一个产品评论的简短摘要。\n",
      "\n",
      "请对三个反引号之间的评论文本进行概括，最多30个字，并且侧重在快递服务上。\n",
      "\n",
      "评论: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "快递提前到货，公仔可爱但有点小。\n",
      "\n",
      "通过输出结果，我们可以看到，文本以“快递提前到货”开头，体现了对于快递效率的侧重。\n",
      "\n",
      "1.2.2 侧重于价格与质量\n",
      "\n",
      "```python prompt = f\"\"\" 您的任务是从电子商务网站上生成一个产品评论的简短摘要。\n",
      "\n",
      "请对三个反引号之间的评论文本进行概括，最多30个词汇，并且侧重在产品价格和质量上。\n",
      "\n",
      "评论: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "可爱的熊猫公仔，质量好但有点小，价格稍高。快递提前到货。\n",
      "\n",
      "通过输出的结果，我们可以看到，文本以“可爱的熊猫公仔，质量好但有点小，价格稍高”开头，体现了对于产品价格与质量的侧重。\n",
      "\n",
      "1.3 关键信息提取\n",
      "\n",
      "在1.2节中，虽然我们通过添加关键角度侧重的 Prompt ，确实让文本摘要更侧重于某一特定方面，然而，我们可以发现，在结果中也会保留一些其他信息，比如偏重价格与质量角度的概括中仍保留了“快递提前到货”的信息。如果我们只想要提取某一角度的信息，并过滤掉其他所有信息，则可以要求 LLM 进行 文本提取（Extract） 而非概括( Summarize )。\n",
      "\n",
      "下面让我们来一起来对文本进行提取信息吧！\n",
      "\n",
      "```python prompt = f\"\"\" 您的任务是从电子商务网站上的产品评论中提取相关信息。\n",
      "\n",
      "请从以下三个反引号之间的评论文本中提取产品运输相关的信息，最多30个词汇。\n",
      "\n",
      "评论: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "产品运输相关的信息：快递提前一天到货。\n",
      "\n",
      "二、同时概括多条文本\n",
      "\n",
      "在实际的工作流中，我们往往要处理大量的评论文本，下面的示例将多条用户评价集合在一个列表中，并利用 for 循环和文本概括（Summarize）提示词，将评价概括至小于 20 个词以下，并按顺序打印。当然，在实际生产中，对于不同规模的评论文本，除了使用 for 循环以外，还可能需要考虑整合评论、分布式等方法提升运算效率。您可以搭建主控面板，来总结大量用户评论，以及方便您或他人快速浏览，还可以点击查看原评论。这样，您就能高效掌握顾客的所有想法。\n",
      "\n",
      "```python review_1 = prod_review\n",
      "\n",
      "一盏落地灯的评论\n",
      "\n",
      "review_2 = \"\"\" 我需要一盏漂亮的卧室灯，这款灯不仅具备额外的储物功能，价格也并不算太高。 收货速度非常快，仅用了两天的时间就送到了。 不过，在运输过程中，灯的拉线出了问题，幸好，公司很乐意寄送了一根全新的灯线。 新的灯线也很快就送到手了，只用了几天的时间。 装配非常容易。然而，之后我发现有一个零件丢失了，于是我联系了客服，他们迅速地给我寄来了缺失的零件！ 对我来说，这是一家非常关心客户和产品的优秀公司。 \"\"\"\n",
      "\n",
      "一把电动牙刷的评论\n",
      "\n",
      "review_3 = \"\"\" 我的牙科卫生员推荐了电动牙刷，所以我就买了这款。 到目前为止，电池续航表现相当不错。 初次充电后，我在第一周一直将充电器插着，为的是对电池进行条件养护。 过去的3周里，我每天早晚都使用它刷牙，但电池依然维持着原来的充电状态。 不过，牙刷头太小了。我见过比这个牙刷头还大的婴儿牙刷。 我希望牙刷头更大一些，带有不同长度的刷毛， 这样可以更好地清洁牙齿间的空隙，但这款牙刷做不到。 总的来说，如果你能以50美元左右的价格购买到这款牙刷，那是一个不错的交易。 制造商的替换刷头相当昂贵，但你可以购买价格更为合理的通用刷头。 这款牙刷让我感觉就像每天都去了一次牙医，我的牙齿感觉非常干净！ \"\"\"\n",
      "\n",
      "一台搅拌机的评论\n",
      "\n",
      "review_4 = \"\"\" 在11月份期间，这个17件套装还在季节性促销中，售价约为49美元，打了五折左右。 可是由于某种原因（我们可以称之为价格上涨），到了12月的第二周，所有的价格都上涨了， 同样的套装价格涨到了70-89美元不等。而11件套装的价格也从之前的29美元上涨了约10美元。 看起来还算不错，但是如果你仔细看底座，刀片锁定的部分看起来没有前几年版本的那么漂亮。 然而，我打算非常小心地使用它 （例如，我会先在搅拌机中研磨豆类、冰块、大米等坚硬的食物，然后再将它们研磨成所需的粒度， 接着切换到打蛋器刀片以获得更细的面粉，如果我需要制作更细腻/少果肉的食物）。 在制作冰沙时，我会将要使用的水果和蔬菜切成细小块并冷冻 （如果使用菠菜，我会先轻微煮熟菠菜，然后冷冻，直到使用时准备食用。 如果要制作冰糕，我会使用一个小到中号的食物加工器），这样你就可以避免添加过多的冰块。 大约一年后，电机开始发出奇怪的声音。我打电话给客户服务，但保修期已经过期了， 所以我只好购买了另一台。值得注意的是，这类产品的整体质量在过去几年里有所下降 ，所以他们在一定程度上依靠品牌认知和消费者忠诚来维持销售。在大约两天内，我收到了新的搅拌机。 \"\"\"\n",
      "\n",
      "reviews = [review_1, review_2, review_3, review_4]\n",
      "\n",
      "```\n",
      "\n",
      "```python for i in range(len(reviews)): prompt = f\"\"\" 你的任务是从电子商务网站上的产品评论中提取相关信息。\n",
      "\n",
      "请对三个反引号之间的评论文本进行概括，最多20个词汇。\n",
      "\n",
      "评论文本: ```{reviews[i]}```\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(f\"评论{i+1}: \", response, \"\\n\")\n",
      "\n",
      "```\n",
      "\n",
      "评论1:  熊猫公仔是生日礼物，女儿喜欢，软可爱，面部表情和善。价钱有点小，快递提前一天到货。\n",
      "\n",
      "评论2:  漂亮卧室灯，储物功能，快速送达，灯线问题，快速解决，容易装配，关心客户和产品。\n",
      "\n",
      "评论3:  这款电动牙刷电池续航好，但牙刷头太小，价格合理，清洁效果好。\n",
      "\n",
      "评论4:  该评论提到了一个17件套装的产品，在11月份有折扣销售，但在12月份价格上涨。评论者提到了产品的外观和使用方法，并提到了产品质量下降的问题。最后，评论者提到他们购买了另一台搅拌机。\n",
      "\n",
      "三、英文版\n",
      "\n",
      "1.1 单一文本概括\n",
      "\n",
      "python prod_review = \"\"\" Got this panda plush toy for my daughter's birthday, \\ who loves it and takes it everywhere. It's soft and \\ super cute, and its face has a friendly look. It's \\ a bit small for what I paid though. I think there \\ might be other options that are bigger for the \\ same price. It arrived a day earlier than expected, \\ so I got to play with it myself before I gave it \\ to her. \"\"\"\n",
      "\n",
      "```python prompt = f\"\"\" Your task is to generate a short summary of a product \\ review from an ecommerce site.\n",
      "\n",
      "Summarize the review below, delimited by triple backticks, in at most 30 words.\n",
      "\n",
      "Review: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "This panda plush toy is loved by the reviewer's daughter, but they feel it is a bit small for the price.\n",
      "\n",
      "1.2 设置关键角度侧重\n",
      "\n",
      "1.2.1 侧重于快递服务\n",
      "\n",
      "```python prompt = f\"\"\" Your task is to generate a short summary of a product \\ review from an ecommerce site to give feedback to the \\ Shipping deparmtment.\n",
      "\n",
      "Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\ that mention shipping and delivery of the product.\n",
      "\n",
      "Review: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "The customer is happy with the product but suggests offering larger options for the same price. They were pleased with the early delivery.\n",
      "\n",
      "1.2.2 侧重于价格和质量\n",
      "\n",
      "```python prompt = f\"\"\" Your task is to generate a short summary of a product \\ review from an ecommerce site to give feedback to the \\ pricing deparmtment, responsible for determining the \\ price of the product.\n",
      "\n",
      "Summarize the review below, delimited by triple backticks, in at most 30 words, and focusing on any aspects \\ that are relevant to the price and perceived value.\n",
      "\n",
      "Review: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "The customer loves the panda plush toy for its softness and cuteness, but feels it is overpriced compared to other options available.\n",
      "\n",
      "1.3 关键信息提取\n",
      "\n",
      "```python prompt = f\"\"\" Your task is to extract relevant information from \\ a product review from an ecommerce site to give \\ feedback to the Shipping department.\n",
      "\n",
      "From the review below, delimited by triple quotes \\ extract the information relevant to shipping and \\ delivery. Limit to 30 words.\n",
      "\n",
      "Review: {prod_review} \"\"\"\n",
      "\n",
      "response = get_completion(prompt) print(response) ```\n",
      "\n",
      "The shipping department should take note that the product arrived a day earlier than expected.\n",
      "\n",
      "2.1 同时概括多条文本\n",
      "\n",
      "```python review_1 = prod_review\n",
      "\n",
      "review for a standing lamp\n",
      "\n",
      "review_2 = \"\"\" Needed a nice lamp for my bedroom, and this one \\ had additional storage and not too high of a price \\ point. Got it fast - arrived in 2 days. The string \\ to the lamp broke during the transit and the company \\ happily sent over a new one. Came within a few days \\ as well. It was easy to put together. Then I had a \\ missing part, so I contacted their support and they \\ very quickly got me the missing piece! Seems to me \\ to be a great company that cares about their customers \\ and products. \"\"\"\n",
      "\n",
      "review for an electric toothbrush\n",
      "\n",
      "review_3 = \"\"\" My dental hygienist recommended an electric toothbrush, \\ which is why I got this. The battery life seems to be \\ pretty impressive so far. After initial charging and \\ leaving the charger plugged in for the first week to \\ condition the battery, I've unplugged the charger and \\ been using it for twice daily brushing for the last \\ 3 weeks all on the same charge. But the toothbrush head \\ is too small. I’ve seen baby toothbrushes bigger than \\ this one. I wish the head was bigger with different \\ length bristles to get between teeth better because \\ this one doesn’t. Overall if you can get this one \\ around the $50 mark, it's a good deal. The manufactuer's \\ replacements heads are pretty expensive, but you can \\ get generic ones that're more reasonably priced. This \\ toothbrush makes me feel like I've been to the dentist \\ every day. My teeth feel sparkly clean! \"\"\"\n",
      "\n",
      "review for a blender\n",
      "\n",
      "review_4 = \"\"\" So, they still had the 17 piece system on seasonal \\ sale for around $49 in the month of November, about \\ half off, but for some reason (call it price gouging) \\ around the second week of December the prices all went \\ up to about anywhere from between $70-$89 for the same \\ system. And the 11 piece system went up around $10 or \\ so in price also from the earlier sale price of $29. \\ So it looks okay, but if you look at the base, the part \\ where the blade locks into place doesn’t look as good \\ as in previous editions from a few years ago, but I \\ plan to be very gentle with it (example, I crush \\ very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\ I want in the blender then switch to the whipping \\ blade for a finer flour, and use the cross cutting blade \\ first when making smoothies, then use the flat blade \\ if I need them finer/less pulpy). Special tip when making \\ smoothies, finely cut and freeze the fruits and \\ vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\ sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\ much ice if at all-when making your smoothie. \\ After about a year, the motor was making a funny noise. \\ I called customer service but the warranty expired \\ already, so I had to buy another one. FYI: The overall \\ quality has gone done in these types of products, so \\ they are kind of counting on brand recognition and \\ consumer loyalty to maintain sales. Got it in about \\ two days. \"\"\"\n",
      "\n",
      "reviews = [review_1, review_2, review_3, review_4] ```\n",
      "\n",
      "```python for i in range(len(reviews)): prompt = f\"\"\" Your task is to generate a short summary of a product \\ review from an ecommerce site.\n",
      "\n",
      "Summarize the review below, delimited by triple \\\n",
      "backticks in at most 20 words.\n",
      "\n",
      "Review: ```{reviews[i]}```\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(i, response, \"\\n\")\n",
      "\n",
      "```\n",
      "\n",
      "0 Soft and cute panda plush toy loved by daughter, but small for the price. Arrived early.\n",
      "\n",
      "1 Great lamp with storage, fast delivery, excellent customer service, and easy assembly. Highly recommended.\n",
      "\n",
      "2 Impressive battery life, but toothbrush head is too small. Good deal if bought around $50.\n",
      "\n",
      "3 The reviewer found the price increase after the sale disappointing and noticed a decrease in quality over time.\n"
     ]
    }
   ],
   "source": [
    "# 查看部分数据\n",
    "text = texts[1]\n",
    "print(f\"每一个元素的类型：{type(text)}.\", \n",
    "    f\"该文档的描述性数据：{text.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{text.page_content[0:]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档切分\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 构建chroma向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\".env.local\"))\n",
    "\n",
    "def get_embedding(text: str, model: str = None):\n",
    "    # 获取API KEY\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('ARK_API_KEY'),\n",
    "        base_url=os.getenv('ARK_API_URL'),\n",
    "    )\n",
    "\n",
    "    if not model:\n",
    "        model = os.getenv('ARK_EMBEDDING_MODEL')\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response\n",
    "\n",
    "response = get_embedding(text='要生成 embedding 的输入文本，字符串形式。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装Embedding以在langChain中使用\n",
    "from typing import List\n",
    "from langchain_core.embeddings import Embeddings\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "class ArkEmbeddings(Embeddings):\n",
    "\n",
    "    def __init__(self, api_key: str, api_url: str, model: str):\n",
    "        \"\"\"\n",
    "        实例化client.\n",
    "\n",
    "        Args:\n",
    "            api_key (str): 模型key \n",
    "            api_url (str): 模型url\n",
    "            model (str): 模型名\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=api_url,\n",
    "        )\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        生成输入文本列表的 embeddings.\n",
    "\n",
    "        Args:\n",
    "            texts (List[str]): 要生成 embedding 的文本列表.\n",
    "        \n",
    "        Returns:\n",
    "            List[List[float]]: 输入列表中每个文档的 embedding 列表. 每个 embedding 都表示为一个浮点值列表.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        # 每批处理文本\n",
    "        for i in range(0, len(texts), 64):\n",
    "            embeddings = self.client.embeddings.create(\n",
    "                model=self.model,\n",
    "                input=texts[i:i+64]\n",
    "            )\n",
    "            result.extend([embeddings.embedding for embeddings in embeddings.data])\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        生成输入文本的 embedding.\n",
    "\n",
    "        Args:\n",
    "            texts (str): 要生成 embedding 的文本.\n",
    "\n",
    "        Return:\n",
    "            embeddings (List[float]): 输入文本的 embedding, 一个浮点值列表.\n",
    "        \"\"\"\n",
    "        return self.embed_documents([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空存储目录并新建\n",
    "import shutil\n",
    "\n",
    "persist_directory = \"../data_base/vector_db/chroma\"\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    shutil.rmtree(persist_directory)\n",
    "os.makedirs(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding = ArkEmbeddings(\n",
    "    api_key=os.getenv('ARK_API_KEY'),\n",
    "    api_url=os.getenv('ARK_API_URL'),\n",
    "    model=os.getenv('ARK_EMBEDDING_MODEL'),\n",
    ")\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：1004\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 向量检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "# 基于余弦相似度进行检索\n",
    "question = \"什么是大语言模型\"\n",
    "\n",
    "sim_docs = vectordb.similarity_search(question, k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第1个内容：\n",
      "综上，语言模型的幻觉问题事关应用的可靠性与安全性。开发者有必要认识到这一缺陷（注：截至2023年7月），并采取Prompt优化等措施予以缓解，以开发出更加可信赖的语言模型应用。这也将是未来语言模型进化的重要方向之一。\n",
      "\n",
      "注意：\n",
      "\n",
      "关于反斜杠使用的说明：在本教程中，我们使用反斜杠 \\ 来使文本适应屏幕大小以提高阅读体验，而没有用换行符 \\n 。GPT-3 并不受换行符（newline charact\n",
      "--------------\n",
      "检索到的第2个内容：\n",
      "5.1 综合样例\n",
      "--------------\n",
      "检索到的第3个内容：\n",
      "具体来说，首先编写初版 Prompt，然后通过多轮调整逐步改进，直到生成了满意的结果。对于更复杂的应用，可以在多个样本上进行迭代训练，评估 Prompt 的平均表现。在应用较为成熟后，才需要采用在多个样本集上评估 Prompt 性能的方式来进行细致优化。因为这需要较高的计算资源。\n",
      "\n",
      "总之，Prompt 工程师的核心是掌握 Prompt 的迭代开发和优化技巧，而非一开始就要求100%完美。通过不断调\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# 查看检索结果\n",
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i+1}个内容：\\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第1个内容, 相似性打分=5461.279296875：\n",
      "综上，语言模型的幻觉问题事关应用的可靠性与安全性。开发者有必要认识到这一缺陷（注：截至2023年7月），并采取Prompt优化等措施予以缓解，以开发出更加可信赖的语言模型应用。这也将是未来语言模型进化的重要方向之一。\n",
      "\n",
      "注意：\n",
      "\n",
      "关于反斜杠使用的说明：在本教程中，我们使用反斜杠 \\ 来使文本适应屏幕大小以提高阅读体验，而没有用换行符 \\n 。GPT-3 并不受换行符（newline characters）的影响，但在您调用其他大模型时，需额外考虑换行符是否会影响模型性能。\n",
      "\n",
      "四、英文原版 Prompt\n",
      "\n",
      "1.1 使用分隔符清晰地表示输入的不同部分\n",
      "--------------\n",
      "检索到的第2个内容, 相似性打分=5687.2041015625：\n",
      "5.1 综合样例\n",
      "--------------\n",
      "检索到的第3个内容, 相似性打分=5856.32470703125：\n",
      "具体来说，首先编写初版 Prompt，然后通过多轮调整逐步改进，直到生成了满意的结果。对于更复杂的应用，可以在多个样本上进行迭代训练，评估 Prompt 的平均表现。在应用较为成熟后，才需要采用在多个样本集上评估 Prompt 性能的方式来进行细致优化。因为这需要较高的计算资源。\n",
      "\n",
      "总之，Prompt 工程师的核心是掌握 Prompt 的迭代开发和优化技巧，而非一开始就要求100%完美。通过不断调整试错，最终找到可靠适用的 Prompt 形式才是设计 Prompt 的正确方法。\n",
      "\n",
      "读者可以在 Jupyter Notebook 上，对本章给出的示例进行实践，修改 Prompt 并观察不同输出，以深入理解 Prompt 迭代优化的过程。这会对进一步开发复杂语言模型应用提供很好的实践准备。\n",
      "\n",
      "三、英文版\n",
      "\n",
      "产品说明书\n",
      "--------------\n",
      "检索到的第4个内容, 相似性打分=5953.07763671875：\n",
      "is to cherck chatGPT for spelling abilitty\" # spelling ]\n",
      "--------------\n",
      "检索到的第5个内容, 相似性打分=5953.07763671875：\n",
      "is to cherck chatGPT for spelling abilitty\" # spelling ]\n",
      "--------------\n",
      "检索到的第6个内容, 相似性打分=6139.85205078125：\n",
      "第六章 文本转换\n",
      "\n",
      "大语言模型具有强大的文本转换能力，可以实现多语言翻译、拼写纠正、语法调整、格式转换等不同类型的文本转换任务。利用语言模型进行各类转换是它的典型应用之一。\n",
      "\n",
      "在本章中,我们将介绍如何通过编程调用API接口，使用语言模型实现文本转换功能。通过代码示例，读者可以学习将输入文本转换成所需输出格式的具体方法。\n",
      "\n",
      "掌握调用大语言模型接口进行文本转换的技能，是开发各种语言类应用的重要一步。文本转换功能的应用场景也非常广泛。相信读者可以在本章的基础上，利用大语言模型轻松开发出转换功能强大的程序。\n",
      "\n",
      "一、文本翻译\n",
      "\n",
      "文本翻译是大语言模型的典型应用场景之一。相比于传统统计机器翻译系统，大语言模型翻译更加流畅自然，还原度更高。通过在大规模高质量平行语料上进行 Fine-Tune，大语言模型可以深入学习不同语言间的词汇、语法、语义等层面的对应关系，模拟双语者的转换思维，进行意义传递的精准转换，而非简单的逐词替换。\n",
      "--------------\n",
      "检索到的第7个内容, 相似性打分=6198.5849609375：\n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n",
      "\n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "--------------\n",
      "检索到的第8个内容, 相似性打分=6313.24072265625：\n",
      "←_←\n",
      "--------------\n",
      "检索到的第9个内容, 相似性打分=6313.24072265625：\n",
      "←_←\n",
      "--------------\n",
      "检索到的第10个内容, 相似性打分=6696.279296875：\n",
      "在这个例子中，我们已经利用前面章节学到的方法，从客户评价中提取出其表达的情感倾向。这里是一条关于搅拌机的评论。现在我们要基于这条评论中的情感倾向，使用大语言模型自动生成一封回复邮件。\n",
      "\n",
      "以下述 Prompt 为例：首先明确大语言模型的身份是客户服务 AI 助手；它任务是为客户发送电子邮件回复；然后在三个反引号间给出具体的客户评论；最后要求语言模型根据这条反馈邮件生成一封回复，以感谢客户的评价。\n",
      "\n",
      "```python from tool import get_completion\n",
      "\n",
      "prompt = f\"\"\" 你是一位客户服务的AI助手。 你的任务是给一位重要客户发送邮件回复。 根据客户通过“”分隔的评价，生成回复以感谢客户的评价。提醒模型使用评价中的具体细节 用简明而专业的语气写信。 作为“AI客户代理”签署电子邮件。 客户评论：{review}评论情感：{sentiment} \"\"\" response = get_completion(prompt) print(response)\n",
      "\n",
      "尊敬的客户，\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# 基于L2距离进行检索\n",
    "# 只有在明确指定collection_metadata={\"hnsw:space\": \"cosine\"}时才会使用余弦距离\n",
    "sim_docs_with_scores = vectordb.similarity_search_with_score(question, k=10)\n",
    "\n",
    "# 查看检索结果\n",
    "for i, (sim_doc, score) in enumerate(sim_docs_with_scores):\n",
    "    print(f\"检索到的第{i+1}个内容, 相似性打分={score}：\\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于最大边际相关性检索\n",
    "mmr_docs = vectordb.max_marginal_relevance_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第1个内容：\n",
      "综上，语言模型的幻觉问题事关应用的可靠性与安全性。开发者有必要认识到这一缺陷（注：截至2023年7月），并采取Prompt优化等措施予以缓解，以开发出更加可信赖的语言模型应用。这也将是未来语言模型进化的重要方向之一。\n",
      "\n",
      "注意：\n",
      "\n",
      "关于反斜杠使用的说明：在本教程中，我们使用反斜杠 \\ 来使文本适应屏幕大小以提高阅读体验，而没有用换行符 \\n 。GPT-3 并不受换行符（newline charact\n",
      "--------------\n",
      "检索到的第2个内容：\n",
      "5.1 综合样例\n",
      "--------------\n",
      "检索到的第3个内容：\n",
      "is to cherck chatGPT for spelling abilitty\" # spelling ]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# 查看检索结果\n",
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"检索到的第{i+1}个内容：\\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
