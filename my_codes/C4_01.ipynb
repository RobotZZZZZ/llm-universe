{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 å°†LLMæ¥å…¥LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv('.env.local'))\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "api_url = os.getenv(\"DEEPSEEK_API_URL\")\n",
    "model = os.getenv(\"DEEPSEEK_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/llm-universe/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    base_url=api_url,\n",
    "    model_name=model,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke(\"è¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ å¥½å‘€ï¼æˆ‘æ˜¯ **DeepSeek Chat**ï¼Œç”±æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸æ‰“é€ çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚æˆ‘çš„æœ€æ–°ç‰ˆæœ¬æ˜¯ **DeepSeek-V3**ï¼ŒçŸ¥è¯†æˆªæ­¢åˆ° **2024å¹´7æœˆ**ï¼Œæ‹¥æœ‰ **128K ä¸Šä¸‹æ–‡è®°å¿†**ï¼Œå¯ä»¥å¤„ç†è¶…é•¿æ–‡æœ¬ï¼Œè¿˜èƒ½é˜…è¯»å’Œè§£æ **PDFã€Wordã€Excelã€PPTã€TXT** ç­‰æ–‡ä»¶å†…å®¹ã€‚  \\n\\n### **æˆ‘çš„ç‰¹ç‚¹ï¼š**  \\nğŸ”¹ **å…è´¹ä½¿ç”¨**ï¼šç›®å‰ä¸æ”¶è´¹ï¼Œéšæ—¶ä¸ºä½ è§£ç­”é—®é¢˜ï¼  \\nğŸ”¹ **è¶…é•¿ä¸Šä¸‹æ–‡**ï¼šæ”¯æŒé•¿è¾¾ 128K çš„å¯¹è¯è®°å¿†ï¼Œé€‚åˆå¤„ç†å¤æ‚ä»»åŠ¡ã€‚  \\nğŸ”¹ **æ–‡ä»¶é˜…è¯»**ï¼šå¯ä»¥å¸®ä½ åˆ†ææ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚  \\nğŸ”¹ **çŸ¥è¯†ä¸°å¯Œ**ï¼šè¦†ç›–ç§‘æŠ€ã€ç¼–ç¨‹ã€å­¦ä¹ ã€ç”Ÿæ´»ã€å¨±ä¹ç­‰å¤šä¸ªé¢†åŸŸã€‚  \\nğŸ”¹ **é€»è¾‘æ¸…æ™°**ï¼šæ“…é•¿æ¨ç†ã€å†™ä½œã€ç¿»è¯‘ã€ä»£ç ç¼–å†™ç­‰ä»»åŠ¡ã€‚  \\n\\næ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œï¼Œè¿˜æ˜¯æ—¥å¸¸ç”Ÿæ´»ä¸­çš„ç–‘é—®ï¼Œéƒ½å¯ä»¥æ¥æ‰¾æˆ‘èŠèŠï¼ğŸ˜Š ä½ ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å‘¢ï¼Ÿ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 8, 'total_tokens': 226, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 8}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run-1553582b-f98b-473b-9a15-1a507ab9ad7b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 218, 'total_tokens': 226})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'è¯·ä½ å°†ç”±ä¸‰ä¸ªåå¼•å·åˆ†å‰²çš„æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼text: ```æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œæ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚```\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿™é‡Œæˆ‘ä»¬è¦æ±‚æ¨¡å‹å¯¹ç»™å®šæ–‡æœ¬è¿›è¡Œä¸­æ–‡ç¿»è¯‘\n",
    "prompt = \"\"\"è¯·ä½ å°†ç”±ä¸‰ä¸ªåå¼•å·åˆ†å‰²çš„æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼\\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = \"æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œ\\\n",
    "æ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œ\\\n",
    "ç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œ\\\n",
    "ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚\\\n",
    "\"\n",
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘å°† ä¸­æ–‡ ç¿»è¯‘æˆ è‹±æ–‡.', additional_kwargs={}, response_metadata={}), HumanMessage(content='æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œæ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨promptæ¨¡æ¿\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘å°† {input_language} ç¿»è¯‘æˆ {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "\n",
    "text = \"æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œ\\\n",
    "æ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œ\\\n",
    "ç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œ\\\n",
    "ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚\\\n",
    "\"\n",
    "\n",
    "messages = chat_prompt.invoke({\"input_language\": \"ä¸­æ–‡\", \"output_language\": \"è‹±æ–‡\", \"text\": text})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halosâ€”  \\nUnsure if this was the place.  \\n\\n(Note: This translation aims to preserve the poetic and somewhat surreal imagery of the original while ensuring clarity in English. The phrase \"æ¯”èº«ä½“é‡çš„è¡Œæ\" is rendered as \"luggage heavier than my body\" to convey both literal and metaphorical weight. \"æ¸¸å…¥å°¼ç½—æ²³åº•\" becomes \"Dived into the depths of the Nile\" to maintain the sense of submersion and mystery. \"å…‰åœˆ\" is translated as \"halos\" to evoke a luminous, almost otherworldly visual, fitting the dreamlike tone.)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 45, 'total_tokens': 195, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 45}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run-5bcf5386-76d8-481d-9d07-9bda1c295e89-0', usage_metadata={'input_tokens': 45, 'output_tokens': 150, 'total_tokens': 195})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æµ‹è¯•ä¸€ä¸‹\n",
    "output = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halosâ€”  \\nUnsure if this was the place.  \\n\\n(Note: This translation aims to preserve the poetic and somewhat surreal imagery of the original while ensuring clarity in English. The phrase \"æ¯”èº«ä½“é‡çš„è¡Œæ\" is rendered as \"luggage heavier than my body\" to convey both literal and metaphorical weight. \"æ¸¸å…¥å°¼ç½—æ²³åº•\" becomes \"Dived into the depths of the Nile\" to maintain the sense of submersion and mystery. \"å…‰åœˆ\" is translated as \"halos\" to evoke a luminous, almost otherworldly visual, fitting the dreamlike tone.)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ ¼å¼åŒ–è¾“å‡º\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halosâ€”  \\nUnsure if this was the place.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨LCELè¡¨è¾¾å¼\n",
    "chain = chat_prompt | llm | output_parser\n",
    "chain.invoke({\"input_language\": \"ä¸­æ–‡\", \"output_language\": \"è‹±æ–‡\", \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘æ‰›ç€æ¯”èº«ä½“è¿˜é‡çš„è¡Œææ½œå…¥å°¼ç½—æ²³åº•ï¼Œç©¿è¿‡å‡ é“é—ªç”µåçœ‹è§ä¸€å †å…‰æ™•ï¼Œä¸çŸ¥æ˜¯ä¸æ˜¯è¿™é‡Œã€‚'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å†è¯•ä¸€ä¸‹ï¼Œè‹±è¯‘ä¸­\n",
    "text = 'I carried luggage heavier than my body and dived into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, not sure if this is the place.'\n",
    "chain.invoke({\"input_language\": \"è‹±æ–‡\", \"output_language\": \"ä¸­æ–‡\",\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 æ„å»ºæ£€ç´¢é—®ç­”é“¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 åŠ è½½å‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_embedding import ArkEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv('.env.local'))\n",
    "\n",
    "embedding_api_key = os.getenv(\"ARK_API_KEY\")\n",
    "embedding_api_url = os.getenv(\"ARK_API_URL\")\n",
    "embedding_model = os.getenv(\"ARK_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/h44tfn_x35jg4s7msmb1gdzw0000gp/T/ipykernel_7361/801487602.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ– Embeddings\n",
    "embedding = ArkEmbeddings(\n",
    "    api_key=embedding_api_key,\n",
    "    api_url=embedding_api_url,\n",
    "    model=embedding_model,\n",
    ")\n",
    "\n",
    "# å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„\n",
    "persist_directory = \"../data_base/vector_db/chroma\"\n",
    "\n",
    "# åŠ è½½æ•°æ®åº“\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°æ®ï¼š1004\n"
     ]
    }
   ],
   "source": [
    "print(f\"å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°æ®ï¼š{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ£€ç´¢åˆ°çš„å†…å®¹æ•°ï¼š3\n"
     ]
    }
   ],
   "source": [
    "# æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£\n",
    "question = \"ä»€ä¹ˆæ˜¯prompt engineering?\"\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"æ£€ç´¢åˆ°çš„å†…å®¹æ•°ï¼š{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ£€ç´¢åˆ°çš„ç¬¬1ä¸ªå†…å®¹: \n",
      " å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆç¼–å†™åˆç‰ˆ Promptï¼Œç„¶åé€šè¿‡å¤šè½®è°ƒæ•´é€æ­¥æ”¹è¿›ï¼Œç›´åˆ°ç”Ÿæˆäº†æ»¡æ„çš„ç»“æœã€‚å¯¹äºæ›´å¤æ‚çš„åº”ç”¨ï¼Œå¯ä»¥åœ¨å¤šä¸ªæ ·æœ¬ä¸Šè¿›è¡Œè¿­ä»£è®­ç»ƒï¼Œè¯„ä¼° Prompt çš„å¹³å‡è¡¨ç°ã€‚åœ¨åº”ç”¨è¾ƒä¸ºæˆç†Ÿåï¼Œæ‰éœ€è¦é‡‡ç”¨åœ¨å¤šä¸ªæ ·æœ¬é›†ä¸Šè¯„ä¼° Prompt æ€§èƒ½çš„æ–¹å¼æ¥è¿›è¡Œç»†è‡´ä¼˜åŒ–ã€‚å› ä¸ºè¿™éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºã€‚\n",
      "\n",
      "æ€»ä¹‹ï¼ŒPrompt å·¥ç¨‹å¸ˆçš„æ ¸å¿ƒæ˜¯æŒæ¡ Prompt çš„è¿­ä»£å¼€å‘å’Œä¼˜åŒ–æŠ€å·§ï¼Œè€Œéä¸€å¼€å§‹å°±è¦æ±‚100%å®Œç¾ã€‚é€šè¿‡ä¸æ–­è°ƒæ•´è¯•é”™ï¼Œæœ€ç»ˆæ‰¾åˆ°å¯é é€‚ç”¨çš„ Prompt å½¢å¼æ‰æ˜¯è®¾è®¡ Prompt çš„æ­£ç¡®æ–¹æ³•ã€‚\n",
      "\n",
      "è¯»è€…å¯ä»¥åœ¨ Jupyter Notebook ä¸Šï¼Œå¯¹æœ¬ç« ç»™å‡ºçš„ç¤ºä¾‹è¿›è¡Œå®è·µï¼Œä¿®æ”¹ Prompt å¹¶è§‚å¯Ÿä¸åŒè¾“å‡ºï¼Œä»¥æ·±å…¥ç†è§£ Prompt è¿­ä»£ä¼˜åŒ–çš„è¿‡ç¨‹ã€‚è¿™ä¼šå¯¹è¿›ä¸€æ­¥å¼€å‘å¤æ‚è¯­è¨€æ¨¡å‹åº”ç”¨æä¾›å¾ˆå¥½çš„å®è·µå‡†å¤‡ã€‚\n",
      "\n",
      "ä¸‰ã€è‹±æ–‡ç‰ˆ\n",
      "\n",
      "äº§å“è¯´æ˜ä¹¦\n",
      "-----------------------------------------------------\n",
      "æ£€ç´¢åˆ°çš„ç¬¬2ä¸ªå†…å®¹: \n",
      " ç¬¬ä¸€ç«  ç®€ä»‹\n",
      "\n",
      "æ¬¢è¿æ¥åˆ°é¢å‘å¼€å‘è€…çš„æç¤ºå·¥ç¨‹éƒ¨åˆ†ï¼Œæœ¬éƒ¨åˆ†å†…å®¹åŸºäºå´æ©è¾¾è€å¸ˆçš„ã€ŠPrompt Engineering for Developerã€‹è¯¾ç¨‹è¿›è¡Œç¼–å†™ã€‚ã€ŠPrompt Engineering for Developerã€‹è¯¾ç¨‹æ˜¯ç”±å´æ©è¾¾è€å¸ˆä¸ OpenAI æŠ€æœ¯å›¢é˜Ÿæˆå‘˜ Isa Fulford è€å¸ˆåˆä½œæˆè¯¾ï¼ŒIsa è€å¸ˆæ›¾å¼€å‘è¿‡å—æ¬¢è¿çš„ ChatGPT æ£€ç´¢æ’ä»¶ï¼Œå¹¶ä¸”åœ¨æ•™æˆ LLM ï¼ˆLarge Language Modelï¼Œ å¤§è¯­è¨€æ¨¡å‹ï¼‰æŠ€æœ¯åœ¨äº§å“ä¸­çš„åº”ç”¨æ–¹é¢åšå‡ºäº†å¾ˆå¤§è´¡çŒ®ã€‚å¥¹è¿˜å‚ä¸ç¼–å†™äº†æ•™æˆäººä»¬ä½¿ç”¨ Prompt çš„ OpenAI cookbookã€‚æˆ‘ä»¬å¸Œæœ›é€šè¿‡æœ¬æ¨¡å—çš„å­¦ä¹ ï¼Œä¸å¤§å®¶åˆ†äº«ä½¿ç”¨æç¤ºè¯å¼€å‘ LLM åº”ç”¨çš„æœ€ä½³å®è·µå’ŒæŠ€å·§ã€‚\n",
      "-----------------------------------------------------\n",
      "æ£€ç´¢åˆ°çš„ç¬¬3ä¸ªå†…å®¹: \n",
      " ç¬¬äºŒç«  æç¤ºåŸåˆ™\n",
      "\n",
      "å¦‚ä½•å»ä½¿ç”¨ Promptï¼Œä»¥å……åˆ†å‘æŒ¥ LLM çš„æ€§èƒ½ï¼Ÿé¦–å…ˆæˆ‘ä»¬éœ€è¦çŸ¥é“è®¾è®¡ Prompt çš„åŸåˆ™ï¼Œå®ƒä»¬æ˜¯æ¯ä¸€ä¸ªå¼€å‘è€…è®¾è®¡ Prompt æ‰€å¿…é¡»çŸ¥é“çš„åŸºç¡€æ¦‚å¿µã€‚æœ¬ç« è®¨è®ºäº†è®¾è®¡é«˜æ•ˆ Prompt çš„ä¸¤ä¸ªå…³é”®åŸåˆ™ï¼šç¼–å†™æ¸…æ™°ã€å…·ä½“çš„æŒ‡ä»¤å’Œç»™äºˆæ¨¡å‹å……è¶³æ€è€ƒæ—¶é—´ã€‚æŒæ¡è¿™ä¸¤ç‚¹ï¼Œå¯¹åˆ›å»ºå¯é çš„è¯­è¨€æ¨¡å‹äº¤äº’å°¤ä¸ºé‡è¦ã€‚\n",
      "\n",
      "é¦–å…ˆï¼ŒPrompt éœ€è¦æ¸…æ™°æ˜ç¡®åœ°è¡¨è¾¾éœ€æ±‚ï¼Œæä¾›å……è¶³ä¸Šä¸‹æ–‡ï¼Œä½¿è¯­è¨€æ¨¡å‹å‡†ç¡®ç†è§£æˆ‘ä»¬çš„æ„å›¾ï¼Œå°±åƒå‘ä¸€ä¸ªå¤–æ˜Ÿäººè¯¦ç»†è§£é‡Šäººç±»ä¸–ç•Œä¸€æ ·ã€‚è¿‡äºç®€ç•¥çš„ Prompt å¾€å¾€ä½¿æ¨¡å‹éš¾ä»¥æŠŠæ¡æ‰€è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡ã€‚\n",
      "\n",
      "å…¶æ¬¡ï¼Œè®©è¯­è¨€æ¨¡å‹æœ‰å……è¶³æ—¶é—´æ¨ç†ä¹Ÿæä¸ºå…³é”®ã€‚å°±åƒäººç±»è§£é¢˜ä¸€æ ·ï¼ŒåŒ†å¿™å¾—å‡ºçš„ç»“è®ºå¤šæœ‰å¤±è¯¯ã€‚å› æ­¤ Prompt åº”åŠ å…¥é€æ­¥æ¨ç†çš„è¦æ±‚ï¼Œç»™æ¨¡å‹ç•™å‡ºå……åˆ†æ€è€ƒæ—¶é—´ï¼Œè¿™æ ·ç”Ÿæˆçš„ç»“æœæ‰æ›´å‡†ç¡®å¯é ã€‚\n",
      "\n",
      "å¦‚æœ Prompt åœ¨è¿™ä¸¤ç‚¹ä¸Šéƒ½ä½œäº†ä¼˜åŒ–ï¼Œè¯­è¨€æ¨¡å‹å°±èƒ½å¤Ÿå°½å¯èƒ½å‘æŒ¥æ½œåŠ›ï¼Œå®Œæˆå¤æ‚çš„æ¨ç†å’Œç”Ÿæˆä»»åŠ¡ã€‚æŒæ¡è¿™äº› Prompt è®¾è®¡åŸåˆ™ï¼Œæ˜¯å¼€å‘è€…å–å¾—è¯­è¨€æ¨¡å‹åº”ç”¨æˆåŠŸçš„é‡è¦ä¸€æ­¥ã€‚\n",
      "\n",
      "ä¸€ã€åŸåˆ™ä¸€ ç¼–å†™æ¸…æ™°ã€å…·ä½“çš„æŒ‡ä»¤\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# æ‰“å°æ£€ç´¢å†…å®¹\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"æ£€ç´¢åˆ°çš„ç¬¬{i+1}ä¸ªå†…å®¹: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 åˆ›å»ºæ£€ç´¢é“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1 ç»¼åˆæ ·ä¾‹\\n\\næœ€æ–°ç‰ˆPDF è·å–åœ°å€ï¼šhttps://github.com/datawhalechina/pumpkin-book/releases\\nç¼–å§”ä¼š\\nä¸»ç¼–ï¼šSm1lesã€archwalkerã€jbb0523\\nç¼–å§”ï¼šjuxiaoã€Majingminã€MrBigFanã€shanryã€Ye980226\\nå°é¢è®¾è®¡ï¼šæ„æ€-Sm1lesã€åˆ›ä½œ-æ—ç‹èŒ‚ç››\\nè‡´è°¢\\nç‰¹åˆ«æ„Ÿè°¢awyd234ã€feijuanã€Ggmatchã€Heitao5200ã€huaqing89ã€LongJHã€LilRachelã€LeoLRHã€Nono17ã€\\nspareribsã€sunchaothuã€StevenLzq åœ¨æœ€æ—©æœŸçš„æ—¶å€™å¯¹å—ç“œä¹¦æ‰€åšçš„è´¡çŒ®ã€‚\\næ‰«æä¸‹æ–¹äºŒç»´ç ï¼Œç„¶åå›å¤å…³é”®è¯â€œå—ç“œä¹¦â€ï¼Œå³å¯åŠ å…¥â€œå—ç“œä¹¦è¯»è€…äº¤æµç¾¤â€\\nç‰ˆæƒå£°æ˜\\næœ¬ä½œå“é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº«4.0 å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯ã€‚\\n\\nâ†_â†'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "combiner = RunnableLambda(combine_docs)\n",
    "retrieval_chain = retriever | combiner\n",
    "\n",
    "retrieval_chain.invoke(\"å—ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
