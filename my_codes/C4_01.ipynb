{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 将LLM接入LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv('.env.local'))\n",
    "\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "api_url = os.getenv(\"DEEPSEEK_API_URL\")\n",
    "model = os.getenv(\"DEEPSEEK_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/young/project/llmProject/llm-universe/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    base_url=api_url,\n",
    "    model_name=model,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke(\"请你自我介绍一下自己！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好呀！我是 **DeepSeek Chat**，由深度求索（DeepSeek）公司打造的智能 AI 助手。我的最新版本是 **DeepSeek-V3**，知识截止到 **2024年7月**，拥有 **128K 上下文记忆**，可以处理超长文本，还能阅读和解析 **PDF、Word、Excel、PPT、TXT** 等文件内容。  \\n\\n### **我的特点：**  \\n🔹 **免费使用**：目前不收费，随时为你解答问题！  \\n🔹 **超长上下文**：支持长达 128K 的对话记忆，适合处理复杂任务。  \\n🔹 **文件阅读**：可以帮你分析文档内容，提取关键信息。  \\n🔹 **知识丰富**：覆盖科技、编程、学习、生活、娱乐等多个领域。  \\n🔹 **逻辑清晰**：擅长推理、写作、翻译、代码编写等任务。  \\n\\n无论是学习、工作，还是日常生活中的疑问，都可以来找我聊聊！😊 你今天有什么想了解的呢？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 8, 'total_tokens': 226, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 8}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run-1553582b-f98b-473b-9a15-1a507ab9ad7b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 218, 'total_tokens': 226})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请你将由三个反引号分割的文本翻译成英文！text: ```我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。```\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里我们要求模型对给定文本进行中文翻译\n",
    "prompt = \"\"\"请你将由三个反引号分割的文本翻译成英文！\\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个翻译助手，可以帮助我将 中文 翻译成 英文.', additional_kwargs={}, response_metadata={}), HumanMessage(content='我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用prompt模板\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"你是一个翻译助手，可以帮助我将 {input_language} 翻译成 {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "\n",
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "\n",
    "messages = chat_prompt.invoke({\"input_language\": \"中文\", \"output_language\": \"英文\", \"text\": text})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halos—  \\nUnsure if this was the place.  \\n\\n(Note: This translation aims to preserve the poetic and somewhat surreal imagery of the original while ensuring clarity in English. The phrase \"比身体重的行李\" is rendered as \"luggage heavier than my body\" to convey both literal and metaphorical weight. \"游入尼罗河底\" becomes \"Dived into the depths of the Nile\" to maintain the sense of submersion and mystery. \"光圈\" is translated as \"halos\" to evoke a luminous, almost otherworldly visual, fitting the dreamlike tone.)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 45, 'total_tokens': 195, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 45}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run-5bcf5386-76d8-481d-9d07-9bda1c295e89-0', usage_metadata={'input_tokens': 45, 'output_tokens': 150, 'total_tokens': 195})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一下\n",
    "output = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halos—  \\nUnsure if this was the place.  \\n\\n(Note: This translation aims to preserve the poetic and somewhat surreal imagery of the original while ensuring clarity in English. The phrase \"比身体重的行李\" is rendered as \"luggage heavier than my body\" to convey both literal and metaphorical weight. \"游入尼罗河底\" becomes \"Dived into the depths of the Nile\" to maintain the sense of submersion and mystery. \"光圈\" is translated as \"halos\" to evoke a luminous, almost otherworldly visual, fitting the dreamlike tone.)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格式化输出\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I carried luggage heavier than my body,  \\nDived into the depths of the Nile,  \\nThrough several flashes of lightning,  \\nI saw a cluster of halos—  \\nUnsure if this was the place.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用LCEL表达式\n",
    "chain = chat_prompt | llm | output_parser\n",
    "chain.invoke({\"input_language\": \"中文\", \"output_language\": \"英文\", \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我扛着比身体还重的行李潜入尼罗河底，穿过几道闪电后看见一堆光晕，不知是不是这里。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再试一下，英译中\n",
    "text = 'I carried luggage heavier than my body and dived into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, not sure if this is the place.'\n",
    "chain.invoke({\"input_language\": \"英文\", \"output_language\": \"中文\",\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 构建检索问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 加载向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_embedding import ArkEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv('.env.local'))\n",
    "\n",
    "embedding_api_key = os.getenv(\"ARK_API_KEY\")\n",
    "embedding_api_url = os.getenv(\"ARK_API_URL\")\n",
    "embedding_model = os.getenv(\"ARK_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7r/h44tfn_x35jg4s7msmb1gdzw0000gp/T/ipykernel_7361/801487602.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# 初始化 Embeddings\n",
    "embedding = ArkEmbeddings(\n",
    "    api_key=embedding_api_key,\n",
    "    api_url=embedding_api_url,\n",
    "    model=embedding_model,\n",
    ")\n",
    "\n",
    "# 向量数据库持久化路径\n",
    "persist_directory = \"../data_base/vector_db/chroma\"\n",
    "\n",
    "# 加载数据库\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数据：1004\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数据：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "# 检索相似文档\n",
    "question = \"什么是prompt engineering?\"\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"检索到的内容数：{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第1个内容: \n",
      " 具体来说，首先编写初版 Prompt，然后通过多轮调整逐步改进，直到生成了满意的结果。对于更复杂的应用，可以在多个样本上进行迭代训练，评估 Prompt 的平均表现。在应用较为成熟后，才需要采用在多个样本集上评估 Prompt 性能的方式来进行细致优化。因为这需要较高的计算资源。\n",
      "\n",
      "总之，Prompt 工程师的核心是掌握 Prompt 的迭代开发和优化技巧，而非一开始就要求100%完美。通过不断调整试错，最终找到可靠适用的 Prompt 形式才是设计 Prompt 的正确方法。\n",
      "\n",
      "读者可以在 Jupyter Notebook 上，对本章给出的示例进行实践，修改 Prompt 并观察不同输出，以深入理解 Prompt 迭代优化的过程。这会对进一步开发复杂语言模型应用提供很好的实践准备。\n",
      "\n",
      "三、英文版\n",
      "\n",
      "产品说明书\n",
      "-----------------------------------------------------\n",
      "检索到的第2个内容: \n",
      " 第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n",
      "-----------------------------------------------------\n",
      "检索到的第3个内容: \n",
      " 第二章 提示原则\n",
      "\n",
      "如何去使用 Prompt，以充分发挥 LLM 的性能？首先我们需要知道设计 Prompt 的原则，它们是每一个开发者设计 Prompt 所必须知道的基础概念。本章讨论了设计高效 Prompt 的两个关键原则：编写清晰、具体的指令和给予模型充足思考时间。掌握这两点，对创建可靠的语言模型交互尤为重要。\n",
      "\n",
      "首先，Prompt 需要清晰明确地表达需求，提供充足上下文，使语言模型准确理解我们的意图，就像向一个外星人详细解释人类世界一样。过于简略的 Prompt 往往使模型难以把握所要完成的具体任务。\n",
      "\n",
      "其次，让语言模型有充足时间推理也极为关键。就像人类解题一样，匆忙得出的结论多有失误。因此 Prompt 应加入逐步推理的要求，给模型留出充分思考时间，这样生成的结果才更准确可靠。\n",
      "\n",
      "如果 Prompt 在这两点上都作了优化，语言模型就能够尽可能发挥潜力，完成复杂的推理和生成任务。掌握这些 Prompt 设计原则，是开发者取得语言模型应用成功的重要一步。\n",
      "\n",
      "一、原则一 编写清晰、具体的指令\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 打印检索内容\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"检索到的第{i+1}个内容: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 创建检索链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.1 综合样例\\n\\n最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\\n编委会\\n主编：Sm1les、archwalker、jbb0523\\n编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\\n封面设计：构思-Sm1les、创作-林王茂盛\\n致谢\\n特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、\\nspareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\\n扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\\n版权声明\\n本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\\n\\n←_←'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "combiner = RunnableLambda(combine_docs)\n",
    "retrieval_chain = retriever | combiner\n",
    "\n",
    "retrieval_chain.invoke(\"南瓜书是什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 创建LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好呀！我是 **DeepSeek Chat**，由深度求索公司（DeepSeek）研发的一款智能AI助手。我的核心版本是 **DeepSeek-V3**，知识截止到 **2024年7月**，拥有 **128K 上下文记忆**，可以处理超长文本，还能阅读 **PDF、Word、Excel、PPT、TXT** 等文件，帮助你高效获取信息！  \\n\\n✨ **我的特点**：  \\n- **免费使用**：目前不收费，随时为你解答问题！  \\n- **强大的理解与创作能力**：无论是学习、写作、编程、办公还是生活建议，我都能帮上忙。  \\n- **超长上下文支持**：可以记住更长的对话内容，适合处理复杂任务。  \\n- **文件阅读**：上传文档，我可以帮你总结、提取关键信息或分析内容。  \\n\\n如果你有任何问题，无论是学术研究、代码编写、文案创作，还是日常闲聊，都可以找我聊聊！😊 你今天想了解什么呢？'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    base_url=api_url,\n",
    "    model_name=model,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "llm.invoke(\"请你自我介绍一下自己！\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 构建检索问答链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 让模型根据检索的结果，回答问题\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。请你在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {input}\n",
    "\"\"\"\n",
    "\n",
    "# 将template通过 PromptTemplate 转为可以在LCEL中使用的类型\n",
    "prompt = PromptTemplate(template=template)\n",
    "\n",
    "# 处理流程\n",
    "# 1. 获取检索结果，并保留原有的输入\n",
    "# 2. 拼装prompt\n",
    "# 3. 请求llm\n",
    "# 4. 格式化输出\n",
    "qa_chain = (\n",
    "    RunnableParallel({\"context\": retrieval_chain, \"input\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用知识库\n",
    "# 效果测试\n",
    "question_1 = \"什么是南瓜书？\"\n",
    "question_2 = \"Prompt Engineering for Developer是谁写的？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "南瓜书是一本由Datawhale社区编撰的书籍，最新版PDF可通过GitHub获取。它由多位编委和贡献者共同完成，采用知识共享许可协议发布。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain.invoke(question_1)\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_2 的结果：\n",
      "《Prompt Engineering for Developer》是由吴恩达与OpenAI的Isa Fulford合作编写的。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain.invoke(question_2)\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**南瓜书（PumpkinBook）** 是《机器学习》（西瓜书，周志华著）的**公式推导补充手册**，由开源学习社区Datawhale团队发起编写。它旨在帮助读者更深入地理解西瓜书中因篇幅限制未详细展开的数学推导和难点，尤其适合数学基础较弱的读者补充学习。\\n\\n---\\n\\n### **关键信息：**\\n1. **名称由来**  \\n   - 《机器学习》因封面有西瓜被昵称“西瓜书”，而配套的推导手册延续这一风格，取名“南瓜书”（Pumpkin Book）。\\n\\n2. **核心内容**  \\n   - 对西瓜书中**关键公式的详细推导**（如支持向量机、神经网络、概率图模型等章节的数学细节）。\\n   - 补充相关数学知识（如矩阵求导、概率论等），降低学习门槛。\\n\\n3. **特点**  \\n   - **开源免费**：项目托管在GitHub，可随时查阅或贡献。\\n   - **社区驱动**：由多名志愿者合作完成，持续迭代更新。\\n   - **配套资源**：部分版本提供习题解析或代码实现。\\n\\n4. **适用人群**  \\n   - 机器学习初学者，尤其是数学基础薄弱者。\\n   - 希望深入理解西瓜书理论细节的读者。\\n\\n---\\n\\n### **获取方式：**\\n- **GitHub仓库**：搜索 `datawhalechina/pumpkin-book` 可找到最新版本。\\n- **PDF下载**：通常可在仓库的Release页面或社区论坛获取。\\n\\n---\\n\\n### **与其他资料的关系：**\\n- 南瓜书与《机器学习》（西瓜书）**配套使用**，而非独立教材。\\n- 类似资源还有《西瓜书习题解答》等，但南瓜书更聚焦公式推导。\\n\\n如果需要具体章节的推导示例或进一步解读，可以告知具体问题哦！'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不使用知识库\n",
    "# 效果测试\n",
    "llm.invoke(question_1).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《Prompt Engineering for Developer》是由 **DeepLearning.AI** 与 **OpenAI** 合作推出的课程内容，主要作者和讲师是 **Andrew Ng（吴恩达）** 和 **Isa Fulford（OpenAI 的技术团队成员）**。  \\n\\n### 关键点：\\n1. **Andrew Ng** 是 DeepLearning.AI 的创始人，也是机器学习领域的知名教育家（曾任斯坦福大学教授、Coursera 联合创始人）。  \\n2. **Isa Fulford** 是 OpenAI 的开发者关系工程师，专注于帮助开发者有效使用 OpenAI 的 API 和工具。  \\n3. 这门课程是 **免费短期课程**，专注于教授开发者如何通过提示工程（Prompt Engineering）优化大语言模型（如 ChatGPT）的应用。  \\n\\n### 课程内容：\\n- 基础提示设计技巧  \\n- 迭代优化提示的方法  \\n- 构建实际应用（如聊天机器人、文本摘要等）  \\n\\n课程可通过 DeepLearning.AI 官网或 Coursera 平台访问。如果需要链接或进一步信息，可以告诉我！'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(question_2).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从上述的结果来看，增加了知识库，LLM的回答效果，并没有明显的变好，甚至有一些劣化，\n",
    "- 可能是因为这个问题有些旧了，且专业性不够强。\n",
    "- 也有可能是prompt里，对回复的长度进行了强限制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 向检索链添加聊天记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 问答链的系统prompt\n",
    "system_prompt = (\n",
    "    \"你是一个问答任务的助手。 \"\n",
    "    \"请使用检索到的上下文片段回答这个问题。 \"\n",
    "    \"如果你不知道答案就说不知道。 \"\n",
    "    \"请使用简洁的话语回答用户。\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# 制定prompt template\n",
    "qa_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个问答任务的助手。 请使用检索到的上下文片段回答这个问题。 如果你不知道答案就说不知道。 请使用简洁的话语回答用户。\n",
      "\n",
      "\n",
      "南瓜书是什么？\n"
     ]
    }
   ],
   "source": [
    "# 无历史记录\n",
    "messages = qa_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"南瓜书是什么？\",\n",
    "        \"chat_history\": [],\n",
    "        \"context\": \"\"\n",
    "    }\n",
    ")\n",
    "for message in messages.messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个问答任务的助手。 请使用检索到的上下文片段回答这个问题。 如果你不知道答案就说不知道。 请使用简洁的话语回答用户。\n",
      "\n",
      "\n",
      "西瓜书是什么？\n",
      "西瓜书是指周志华老师的《机器学习》一书，是机器学习领域的经典入门教材之一。\n",
      "你可以介绍一下他吗？\n"
     ]
    }
   ],
   "source": [
    "# 有历史记录\n",
    "messages = qa_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"你可以介绍一下他吗？\",\n",
    "        \"chat_history\": [\n",
    "            (\"human\", \"西瓜书是什么？\"),\n",
    "            (\"ai\", \"西瓜书是指周志华老师的《机器学习》一书，是机器学习领域的经典入门教材之一。\"),\n",
    "        ],\n",
    "        \"context\": \"\"\n",
    "    }\n",
    ")\n",
    "for message in messages.messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看到，上述的方案，只是简单地将历史的文本和当前的问题进行拼接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6 带有信息压缩的检索链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# 压缩问题的系统 prompt\n",
    "condense_question_system_template = (\n",
    "    \"请根据聊天记录完善用户最新的问题，\"\n",
    "    \"如果用户最新的问题不需要完善则返回用户的问题。\"\n",
    "    \"确保最后的输出是一个完整的问题。\"  # NOTE: 这里需要确保最后的输出是一个完整的问题\n",
    ")\n",
    "\n",
    "# 构建压缩问题的 prompt template\n",
    "condense_question_prompt = ChatPromptTemplate([\n",
    "    (\"system\", condense_question_system_template),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 构造“总结历史信息”的检索文档的处理链\n",
    "# RunnableBranch 会根据条件选择要运行的分支\n",
    "retrieve_docs = RunnableBranch(\n",
    "    # 分支 1: 若聊天记录中没有 chat_history 则直接使用用户问题查询向量数据库\n",
    "    (lambda x: not x.get(\"chat_history\", \"\"), (lambda x: x[\"input\"]) | retriever, ),\n",
    "    # 分支 2 : 若聊天记录中有 chat_history 则先让 llm 根据聊天记录完善问题再查询向量数据库\n",
    "    condense_question_prompt | llm | StrOutputParser() | retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'南瓜书跟它有什么关系？'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 原问题\n",
    "test_chain = condense_question_prompt | llm | StrOutputParser()\n",
    "test_chain.invoke({\n",
    "    \"input\": \"南瓜书跟它有什么关系？\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'南瓜书和西瓜书有什么关系？'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 完善信息后的问题\n",
    "test_chain = condense_question_prompt | llm | StrOutputParser()\n",
    "test_chain.invoke({\n",
    "    \"input\": \"南瓜书跟它有什么关系？\",\n",
    "    \"chat_history\": [\n",
    "        (\"human\", \"西瓜书是什么？\"),\n",
    "        (\"ai\", \"西瓜书是指周志华老师的《机器学习》一书，是机器学习领域的经典入门教材之一。\"),\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义 combine_docs\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs[\"context\"])\n",
    "\n",
    "# 定义“整合知识库”的问答链\n",
    "# 1. 整合知识库信息进入context\n",
    "# 2. 拼装prompt, 整合context和chat_history进入qa_chain\n",
    "# 3. 请求llm\n",
    "# 4. 格式化输出\n",
    "qa_chain = (\n",
    "    RunnablePassthrough.assign(context=combine_docs) # 使用 combine_docs 函数，整合知识库的内容得到context输入 qa_prompt\n",
    "    | qa_prompt # 问答模板\n",
    "    | llm\n",
    "    | StrOutputParser() # 规定输出的格式为 str\n",
    ")\n",
    "\n",
    "# 定义带有历史记录的问答链\n",
    "# 1. 检索知识库(结合总结历史信息), 并存入context\n",
    "# 2. 整合context和chat_history进入qa_chain\n",
    "qa_history_chain = RunnablePassthrough.assign(\n",
    "    context=retrieve_docs # 将查询结果存为 context\n",
    ").assign(answer=qa_chain) # 将最终结果存为 answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chat_history在两个地方使用了:\n",
    "- 1.检索知识库时；\n",
    "- 2.在请求llm时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '西瓜书是什么？',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 13, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n第1 章\\n绪论\\n本章作为“西瓜书”的开篇，主要讲解什么是机器学习以及机器学习的相关数学符号，为后续内容作\\n铺垫，并未涉及复杂的算法理论，因此阅读本章时只需耐心梳理清楚所有概念和数学符号即可。此外，在\\n阅读本章前建议先阅读西瓜书目录前页的《主要符号表》，它能解答在阅读“西瓜书”过程中产生的大部\\n分对数学符号的疑惑。\\n本章也作为本书的开篇，笔者在此赘述一下本书的撰写初衷，本书旨在以“过来人”的视角陪读者一\\n起阅读“西瓜书”，尽力帮读者消除阅读过程中的“数学恐惧”，只要读者学习过《高等数学》、《线性代\\n数》和《概率论与数理统计》这三门大学必修的数学课，均能看懂本书对西瓜书中的公式所做的解释和推\\n导，同时也能体会到这三门数学课在机器学习上碰撞产生的“数学之美”。\\n1.1\\n引言\\n本节以概念理解为主，在此对“算法”和“模型”作补充说明。“算法”是指从数据中学得“模型”的具\\n体方法，例如后续章节中将会讲述的线性回归、对数几率回归、决策树等。“算法”产出的结果称为“模型”，'),\n",
       "  Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 44, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n第4 章\\n决策树\\n本章的决策树算法背后没有复杂的数学推导，其更符合人类日常思维方式，理解起来也更为直观，其\\n引入的数学工具也仅是为了让该算法在计算上可行，同时“西瓜书”在本章列举了大量例子，因此本章的\\n算法会更为通俗易懂。\\n4.1\\n基本流程\\n作为本章的开篇，首先要明白决策树在做什么。正如“西瓜书”中图4.1 所示的决策过程，决策树就\\n是不断根据某属性进行划分的过程（每次决策时都是在上次决策结果的基础之上进行），即“if⋯⋯elif⋯⋯\\nelse⋯⋯”的决策过程，最终得出一套有效的判断逻辑，便是学到的模型。但是，划分到什么时候就停止\\n划分呢？这就是图4.2 中的3 个“return”代表的递归返回，下面解释图4.2 中的3 个递归返回。\\n首先，应该明白决策树的基本思想是根据某种原则（即图4.2 第8 行）每次选择一个属性作为划分依\\n据，然后按属性的取值将数据集中的样本进行划分，例如将所有触感为“硬滑”的西瓜的分到一起，将所\\n有触感为“软粘”的西瓜分到一起，划分完得到若干子集，接着再对各个子集按照以上流程重新选择某个'),\n",
       "  Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 58, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n5.6\\n深度学习\\n“西瓜书”在本节并未对如今深度学习领域的诸多经典神经网络作展开介绍，而是从更宏观的角度详\\n细解释了应该如何理解深度学习。因此，本书也顺着“西瓜书”的思路对深度学习相关概念作进一步说明，\\n对深度学习的经典神经网络感兴趣的读者可查阅其他相关书籍进行系统性学习。\\n5.6.1\\n什么是深度学习\\n深度学习就是很深层的神经网络，而神经网络属于机器学习算法的范畴，因此深度学习是机器学习的\\n子集。\\n5.6.2\\n深度学习的起源\\n深度学习中的经典神经网络以及用于训练神经网络的BP 算法其实在很早就已经被提出，例如卷积神\\n经网络\\n[2] 是在1989 提出，BP 算法\\n[3] 是在1986 年提出，但是在当时的计算机算力水平下，其他非神经\\n网络类算法（例如当时红极一时的支持向量机算法）的效果优于神经网络类算法，因此神经网络类算法进\\n入瓶颈期。随着计算机算力的不断提升，以及2012 年Hinton 和他的学生提出了AlexNet 并在ImageNet')],\n",
       " 'answer': '西瓜书是《机器学习》一书的昵称，由周志华教授编写，是机器学习领域的经典教材。南瓜书《机器学习公式详解》是对西瓜书中公式的详细解释和推导，适合作为辅助阅读材料。'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试检索问答链\n",
    "# 不带聊天记录\n",
    "qa_history_chain.invoke({\n",
    "    \"input\": \"西瓜书是什么？\",\n",
    "    \"chat_history\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '南瓜书跟它有什么关系？',\n",
       " 'chat_history': [('human', '西瓜书是什么？'),\n",
       "  ('ai', '西瓜书是指周志华老师的《机器学习》一书，是机器学习领域的经典入门教材之一。')],\n",
       " 'context': [Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 13, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n第1 章\\n绪论\\n本章作为“西瓜书”的开篇，主要讲解什么是机器学习以及机器学习的相关数学符号，为后续内容作\\n铺垫，并未涉及复杂的算法理论，因此阅读本章时只需耐心梳理清楚所有概念和数学符号即可。此外，在\\n阅读本章前建议先阅读西瓜书目录前页的《主要符号表》，它能解答在阅读“西瓜书”过程中产生的大部\\n分对数学符号的疑惑。\\n本章也作为本书的开篇，笔者在此赘述一下本书的撰写初衷，本书旨在以“过来人”的视角陪读者一\\n起阅读“西瓜书”，尽力帮读者消除阅读过程中的“数学恐惧”，只要读者学习过《高等数学》、《线性代\\n数》和《概率论与数理统计》这三门大学必修的数学课，均能看懂本书对西瓜书中的公式所做的解释和推\\n导，同时也能体会到这三门数学课在机器学习上碰撞产生的“数学之美”。\\n1.1\\n引言\\n本节以概念理解为主，在此对“算法”和“模型”作补充说明。“算法”是指从数据中学得“模型”的具\\n体方法，例如后续章节中将会讲述的线性回归、对数几率回归、决策树等。“算法”产出的结果称为“模型”，'),\n",
       "  Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 10, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n12.7.4 式(12.60) 的推导. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n149\\n12.7.5 经验损失最小化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n149\\n12.7.6 定理(12.9) 的证明的解释. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n150\\n第13 章半监督学习\\n151\\n13.1 未标记样本. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n151'),\n",
       "  Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 58, 'producer': 'xdvipdfmx (20200315)', 'source': '../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←\\n5.6\\n深度学习\\n“西瓜书”在本节并未对如今深度学习领域的诸多经典神经网络作展开介绍，而是从更宏观的角度详\\n细解释了应该如何理解深度学习。因此，本书也顺着“西瓜书”的思路对深度学习相关概念作进一步说明，\\n对深度学习的经典神经网络感兴趣的读者可查阅其他相关书籍进行系统性学习。\\n5.6.1\\n什么是深度学习\\n深度学习就是很深层的神经网络，而神经网络属于机器学习算法的范畴，因此深度学习是机器学习的\\n子集。\\n5.6.2\\n深度学习的起源\\n深度学习中的经典神经网络以及用于训练神经网络的BP 算法其实在很早就已经被提出，例如卷积神\\n经网络\\n[2] 是在1989 提出，BP 算法\\n[3] 是在1986 年提出，但是在当时的计算机算力水平下，其他非神经\\n网络类算法（例如当时红极一时的支持向量机算法）的效果优于神经网络类算法，因此神经网络类算法进\\n入瓶颈期。随着计算机算力的不断提升，以及2012 年Hinton 和他的学生提出了AlexNet 并在ImageNet')],\n",
       " 'answer': '南瓜书《机器学习公式详解》是西瓜书的配套学习资料，主要对西瓜书中的公式进行详细解释和推导，帮助读者更好地理解机器学习中的数学内容。'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 带聊天记录\n",
    "qa_history_chain.invoke({\n",
    "    \"input\": \"南瓜书跟它有什么关系？\",\n",
    "    \"chat_history\": [\n",
    "        (\"human\", \"西瓜书是什么？\"),\n",
    "        (\"ai\", \"西瓜书是指周志华老师的《机器学习》一书，是机器学习领域的经典入门教材之一。\"),\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 部署知识库助手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
