{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多类型文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../notebook/C7 高级 RAG 技巧/2. 数据处理/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 结构化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(os.path.join(data_dir, \"company.csv\"))\n",
    "csv_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取后返回的类型为：<class 'list'>, len=6284\n",
      "每个元素的类型为：<class 'langchain_core.documents.base.Document'>\n",
      "第一个 page_content 中存放的数据为：\n",
      "EmployeeID: 1318\n",
      "birthdate_key: 1/3/1954\n",
      "age: 61\n",
      "city_name: Vancouver\n",
      "department: Executive\n",
      "job_title: CEO\n",
      "gender: M\n",
      "第一个 metadata 中存放的数据为：{'source': '../notebook/C7 高级 RAG 技巧/2. 数据处理/data\\\\company.csv', 'row': 0}\n",
      "metadata 数据类型为：<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"读取后返回的类型为：{type(csv_data)}, len={len(csv_data)}\")\n",
    "print(f\"每个元素的类型为：{type(csv_data[0])}\")\n",
    "# 一行为一个page_content\n",
    "print(f\"第一个 page_content 中存放的数据为：\\n{csv_data[0].page_content}\")\n",
    "print(f\"第一个 metadata 中存放的数据为：{csv_data[0].metadata}\")\n",
    "print(f\"metadata 数据类型为：{type(csv_data[0].metadata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字符串处理的结果为: 工号ID:1318的员工于:1/3/1954出生，现在61岁，居住城市为Vancouver工作部门为Executive职位是CEO性别为M(M为男性F为女性)。\n",
      "metadata中存放的路径为: ../notebook/C7 高级 RAG 技巧/2. 数据处理/data\\company.csv\n",
      "metadata中存放的行号为: 0\n"
     ]
    }
   ],
   "source": [
    "processed_data = csv_data[0].page_content \\\n",
    "                            .replace(\"\\n\", \"\") \\\n",
    "                            .replace(\" \", \"\") \\\n",
    "                            .replace(\"Employee\", \"工号\") \\\n",
    "                            .replace(\"birthdate_key\", \"的员工于\") \\\n",
    "                            .replace(\"age:\", \"出生，现在\") \\\n",
    "                            .replace(\"city_name:\", \"岁，居住城市为\") \\\n",
    "                            .replace('department:', '工作部门为') \\\n",
    "                            .replace('job_title:', '职位是') \\\n",
    "                            .replace('gender:', '性别为')\n",
    "processed_data = processed_data + '(M为男性F为女性)。'\n",
    "print(\"字符串处理的结果为:\", processed_data)\n",
    "print('metadata中存放的路径为:', csv_data[0].metadata['source'])\n",
    "print('metadata中存放的行号为:', csv_data[0].metadata['row'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.非结构化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. PPT文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader\n",
    "loader = UnstructuredPowerPointLoader(os.path.join(data_dir, \"AI视频.pptx\"))\n",
    "ppt_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取后返回的类型为:<class 'list'>\n",
      "读取后返回的长度为:1\n",
      "每个元素的类型为:<class 'langchain_core.documents.base.Document'>\n",
      "第一个 page_content 中存放的数据为:\n",
      "Sora原理与实战\n",
      "\n",
      "动手学习AI视频\n",
      "\n",
      "\n",
      "\n",
      "现有AI视频软件盘点\u000b\n",
      "\n",
      "    随着2023年ChatGPT的爆发，让AI的普及率迅速提升，切实的让人感受到AI的给普通人带来的影响，在2023年火了一年的LLM后，视频领域也是也在2024年迅速崛起，前有前辈Runway，后有新生代产品pika，当然也有大名鼎鼎的开源救星SD的当家产品，Stable Video Diffusion，当这几家视频生成\n",
      "page_content 数据类型为:<class 'str'>\n",
      "metadata 中存放的数据为:{'source': '../notebook/C7 高级 RAG 技巧/2. 数据处理/data\\\\AI视频.pptx'}\n",
      "metadata 数据类型为:<class 'dict'>\n",
      "metadata 存放的 source 为: ../notebook/C7 高级 RAG 技巧/2. 数据处理/data\\AI视频.pptx\n"
     ]
    }
   ],
   "source": [
    "print(f'读取后返回的类型为:{type(ppt_data)}')\n",
    "print(f'读取后返回的长度为:{len(ppt_data)}')\n",
    "print(f'每个元素的类型为:{type(ppt_data[0])}')\n",
    "# 非结构化的数据，所有的数据都存于page_content\n",
    "print(f'第一个 page_content 中存放的数据为:\\n{ppt_data[0].page_content[:200]}')\n",
    "print(f'page_content 数据类型为:{type(ppt_data[0].page_content)}')\n",
    "print(f'metadata 中存放的数据为:{ppt_data[0].metadata}')\n",
    "print(f'metadata 数据类型为:{type(ppt_data[0].metadata)}')\n",
    "print(f'metadata 存放的 source 为:', str(ppt_data[0].metadata['source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的数据为:\n",
      "Sora原理与实战\n",
      "动手学习AI视频\n",
      "现有AI视频软件盘点\u000b\n",
      "随着2023年ChatGPT的爆发，让AI的普及率迅速提升，切实的让人感受到AI的给普通人带来的影响，在2023年火了一年的LLM后，视频领域也是也在2024年迅速崛起，前有前辈Runway，后有新生代产品pika，当然也有大名鼎鼎的开源救星SD的当家产品，StableVideoDiffusion，当这几家视频生成公司互相竞争，抢市场份\n"
     ]
    }
   ],
   "source": [
    "# 将多个\\n替换为一个\\n\n",
    "import re\n",
    "processed_data = re.sub(r'\\n+', '\\n', ppt_data[0].page_content)\n",
    "# 清除空格\n",
    "processed_data = processed_data.replace(\" \", \"\")\n",
    "print(f\"处理后的数据为:\\n{processed_data[:200]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 doc\\docx文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 一次性读取全文内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全文内容: \n",
      "第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Larg\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.word_document import UnstructuredWordDocumentLoader\n",
    "\n",
    "loader = UnstructuredWordDocumentLoader(os.path.join(data_dir, \"1. 简介 Introduction.docx\"), mode=\"single\")\n",
    "docs = loader.load()\n",
    "print(f\"全文内容: \\n{docs[0].page_content[:200]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 按元素读取内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个元素: \n",
      "第一章 简介\n",
      "第1个元素: \n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Langua\n",
      "第2个元素: \n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 Deep\n",
      "第3个元素: \n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "第4个元素: \n",
      "随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如\n",
      "第5个元素: \n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforce\n",
      "第6个元素: \n",
      "因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角\n",
      "第7个元素: \n",
      "如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredWordDocumentLoader(os.path.join(data_dir, \"1. 简介 Introduction.docx\"), mode=\"elements\")\n",
    "docs = loader.load()\n",
    "for i in range(len(docs)):\n",
    "    print(f\"第{i}个元素: \\n{docs[i].page_content[:200]}\", end=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据清洗及脱敏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗前的句子: \n",
      "     llm_universe是一个面向小白开发者的大模型应用开发教程😍😍😍，\n",
      "\n",
      "旨在基于阿里云服务器😆😆😆，\n",
      "\n",
      "\n",
      "结合个人知识库助手项目，\n",
      "通过一个课程完成大模型开发的重点入门。\n",
      "\n",
      "\n",
      "学习llm_universe之后，\n",
      "我才知道大模型应用开发原来这么简单！🌟\n",
      "\n",
      "清洗后的句子: \n",
      "llm_universe是一个面向小白开发者的大模型应用开发教程,旨在基于阿里云服务器,结合个人知识库助手项目,通过一个课程完成大模型开发的重点入门。\n",
      "学习llm_universe之后,我才知道大模型应用开发原来这么简单！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # 给出emoji范围并删除emoji\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[]\"\n",
    "        u\"\\U0001F601-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    text = emoji_pattern.sub(r\"\", text)\n",
    "    # 删除字符串开头的空格\n",
    "    text = re.sub(r\"^\\s+\", \"\", text)\n",
    "    # 将多个回车改为一个\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    # 删除句子中（以逗号结尾）的回车\n",
    "    text = re.sub(r\"，\\n\", \",\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 该字符串中存在重复的空格、换行符以及表情符号\n",
    "text = '''     llm_universe是一个面向小白开发者的大模型应用开发教程😍😍😍，\n",
    "\n",
    "旨在基于阿里云服务器😆😆😆，\n",
    "\n",
    "\n",
    "结合个人知识库助手项目，\n",
    "通过一个课程完成大模型开发的重点入门。\n",
    "\n",
    "\n",
    "学习llm_universe之后，\n",
    "我才知道大模型应用开发原来这么简单！🌟\n",
    "'''\n",
    "\n",
    "cleaned_text = clean_text(text)\n",
    "print(f\"清洗前的句子: \\n{text}\")\n",
    "print(f\"清洗后的句子: \\n{cleaned_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 数据脱敏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_universe的GitHub地址为\n",
      "Datawhale的GitHub地址为\n",
      "大模型实习生小明的邮箱为\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"llm_universe的GitHub地址为https://github.com/datawhalechina/llm-universe\n",
    "Datawhale的GitHub地址为https://github.com/datawhalechina\n",
    "大模型实习生小明的邮箱为xiaoming@gmail.com\"\"\"\n",
    "\n",
    "def remove_urls(text: str):\n",
    "    r\"\"\"\n",
    "    http[s]?://匹配http://或https://，其中[s]?表示可选\n",
    "    ?:匹配后面的文本\n",
    "    [a-zA-Z]匹配大小写字母\n",
    "    [0-9]匹配数字\n",
    "    [$-_@.&+!*\\(\\),]匹配各种符号，其中在左右括号前边加了\\来转译\n",
    "    |意思为或，将所有条件并列起来\n",
    "    (?:%[0-9a-fA-F][0-9a-fA-F])匹配网址中URL编码比如%20，格式为%后加两位数字或字母\n",
    "    \"\"\"\n",
    "    url_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    text = re.sub(url_pattern, \"\", text)\n",
    "\n",
    "    email_pattern = r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\"\n",
    "    text = re.sub(email_pattern, \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "text = remove_urls(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
